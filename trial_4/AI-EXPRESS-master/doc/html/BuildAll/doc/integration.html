

<!DOCTYPE html>
<html class="writer-html4" lang="zh-CN" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>如何集成模型至AI-EXPRESS &mdash; AI Express用户手册 2.9.0 文档</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script type="text/javascript" src="../../_static/translations.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../../genindex.html" />
    <link rel="search" title="搜索" href="../../search.html" />
    <link rel="next" title="常见问题" href="faq.html" />
    <link rel="prev" title="工具集" href="tools.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> AI Express用户手册
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="在文档中搜索" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">快速上手</a></li>
<li class="toctree-l1"><a class="reference internal" href="xstream.html">XStream算法SDK编程框架开发指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="xproto.html">XProto原型应用开发框架开发指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="solution.html">场景参考解决方案</a></li>
<li class="toctree-l1"><a class="reference internal" href="tools.html">工具集</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">如何集成模型至AI-EXPRESS</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">图像获取</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">智能预测</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id3">模型编译</a></li>
<li class="toctree-l3"><a class="reference internal" href="#method">模型预测Method的开发</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dnnasyncdata">DnnAsyncData</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dnnpredictmethod">DnnPredictMethod</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dnnpostprocessmethod">DnnPostProcessMethod</a></li>
<li class="toctree-l4"><a class="reference internal" href="#roi">ROI方式进一步解释</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id4">模型集成的示例</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id5">效果展示</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#customsmartmessage">CustomSmartMessage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#x3-proto">x3.proto</a></li>
<li class="toctree-l3"><a class="reference internal" href="#smartplugin">SmartPlugin</a></li>
<li class="toctree-l3"><a class="reference internal" href="#websocketplugin">WebsocketPlugin</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id6">运行部署</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id7">模型集成示例说明</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id8">模型描述</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id9">模型预测与后处理Method开发</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#yolov3">YoloV3</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mobilenetv2">MobilenetV2</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id10">SmartPlugin</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id11">WebSocketPlugin</a></li>
<li class="toctree-l3"><a class="reference internal" href="#main">main 函数实现</a></li>
<li class="toctree-l3"><a class="reference internal" href="#yolov3-solution">运行yolov3_solution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">常见问题</a></li>
<li class="toctree-l1"><a class="reference internal" href="version.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="copyright.html">版权声明</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">AI Express用户手册</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>如何集成模型至AI-EXPRESS</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/BuildAll/doc/integration.md.txt" rel="nofollow"> 查看页面源码</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="ai-express">
<h1>如何集成模型至AI-EXPRESS<a class="headerlink" href="#ai-express" title="永久链接至标题">¶</a></h1>
<p>当我们使用浮点定点工具转换得到一个异构模型bin文件时，如何集成到AI-Express？</p>
<p>本章节解决该问题！</p>
<p>解决该问题，我们需要关注这几个模块：</p>
<ul class="simple">
<li>图像获取</li>
<li>智能预测</li>
<li>效果展示</li>
<li>运行部署</li>
</ul>
<p>图像获取部分主要是复用XProto中的IotVioPlugin。其中需要修改的地方是金字塔的配置：建议配置金字塔中存在一层图像，该层的分辨率直接是全图检测/分割模型需要的输入大小，避免需要ARM上软件缩放图像。</p>
<p>智能预测模块主要是复用XProto中的SmartPlugin，SmartPlugin内部会调用XStream-Framework接口，完成workflow的计算。集成新模型需要我们关注的主要是这几个地方：模型编译、感知结果数据结构定义、模型预测Method的开发、workflow的构建。</p>
<p>模型编译配置，建议将全图检测/分割模型，编译为NV12输入：因为XJ3上获取到的图像都是NV12图，避免送入检测/分割模型，需要颜色空间转换。对于ROI分类回归模型，则无该建议。</p>
<p>每种模型输出的结果均需要定义一个具体的数据结构，为了能够在XStream-Framework框架中传递，该数据结果需要继承BaseData。</p>
<p>每类模型前后处理不会完全一样，需要继承XStream-Framework框架提供的DnnPredictMethod与DnnPostProcessMethod，分别重写模型的预处理与后处理接口。</p>
<p>效果展示模块需要我们关注的是感知数据结构的序列化接口、AI-Express中定义的xprotobuf数据结构描述文件x3.proto。</p>
<p>运行部署部分主要是解决新增模块的编译、run.sh脚本的更新等。</p>
<p>大的组建框架关系如下图所示：
<img alt="plugin关系" src="../../_images/integration.png" /></p>
<ul class="simple">
<li>IotVioPlugin: 用于获取图像，直接复用，适配新的sensor比较麻烦，暂时建议不要对它做扩展。</li>
<li>SmartPlugin: 从XProto总线上获取图像，调用XStream，完成workflow的预测，向总线推送感知结果消息。感知结果与SmartPlugin均可以通过继承进行扩展，用于支持新的感知消息数据类型。</li>
<li>WebsocketPlugin: 从XProto总线上获取图像与感知结果，对图像进行编码，对感知结果进行序列化，完成图像与感知结果的匹配，通过websocket方式发给PC浏览器。可通过继承进行扩展，支持不同的感知消息类型。</li>
</ul>
<div class="section" id="id1">
<h2>图像获取<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h2>
<p>xproto中的IotVioPlugin提供了图像获取的能力，支持从MIPI Camera、 外接usb camera、本地图像获取图像，计算生成金字塔。</p>
<p>金字塔的原理这里不做详细描述，主要介绍IotVioPlugin如何配置金字塔每层的大小。</p>
<p>目前AI-EXPRESS适配了几种camera以及回灌图像，对于其他camera型号或者回灌图像大小需求，请找地平线相关AE支持。</p>
<p>IotVioPlugin金字塔大小配置的文件在：<strong>xproto/plugins/iotvioplugin/configs/vio/x3dev</strong>目录。该目录有的文件如下：</p>
<p><img alt="vio配置" src="../../_images/vio_files.png" /></p>
<p>只需要关注红色框框住的文件，其他文件是单元测试代码需要。</p>
<p>各个文件的用途说明如下表：</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>文件</th>
<th>功能说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>iot_vio_x3_1080_fb.json</td>
<td>1080P本地图像回灌的金字塔配置</td>
</tr>
<tr>
<td>iot_vio_x3_2160_fb.json</td>
<td>2160P本地图像回灌的金字塔配置</td>
</tr>
<tr>
<td>iot_vio_x3_imx327.json</td>
<td>MIPI camera 327的金字塔配置，原图为1080P</td>
</tr>
<tr>
<td>iot_vio_x3_os8a10.json</td>
<td>MIPI camera os8a10的金字塔配置，原图设置为2160P</td>
</tr>
<tr>
<td>iot_vio_x3_os8a10_1080p.json</td>
<td>MIPI camera os8a10的金字塔配置，原图设置为1080P</td>
</tr>
<tr>
<td>iot_vio_x3_s5kgm1sp.json</td>
<td>MIPI camera s5kgm1sp，原图设置为4000x3000</td>
</tr>
<tr>
<td>iot_vio_x3_s5kgm1sp_2160p.json</td>
<td>MIPI camera s5kgm1sp，原图设置为2160P</td>
</tr>
<tr>
<td>iot_vio_x3_usb_cam_1080p.json</td>
<td>外接usb camera，原图分辨率为1080P</td>
</tr>
</tbody>
</table><p>以上所有文件，金字塔每层的配置都是类似的。以iot_vio_x3_usb_cam_1080p.json为例。</p>
<p>金字塔配置在 <strong>pym_ds_config</strong>这个节点，该节点配置金字塔缩放层。</p>
<p>金字塔包含基本层与缩放层，基本层为0，4，8，12，16，20这6层，图像分辨率分别为原图、原图/2、原图/4等等。 其他层为缩放层，缩放层的缩放范围可以配置，基本层缩放比例上固定的，不需要配置。</p>
<p>金字塔1-3层，为基于基本层0的缩放层；</p>
<p>金字塔5-7层，为基于基本层4的缩放层；以此类推。</p>
<p>通过设置roi_x_i、roi_y_i、roi_w_i、roi_h_i，从对应基本层中扣取该区域ROI；</p>
<p>factor_i用于表示相对对应的基本层，需要缩放的倍数。缩放倍数计算公式为： 64/(64+factor)， factor取值范围为[1-63], factor设置为0表示该层不使能。</p>
<p>最终该缩放层的大小为： ROI * 64/(64+factor)，宽与高分别向下取整。</p>
<p>比如iot_vio_x3_usb_cam_1080p.json这个文件中</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;roi_x_6&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<span class="s2">&quot;roi_y_6&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<span class="s2">&quot;roi_w_6&quot;</span><span class="p">:</span> <span class="mi">960</span><span class="p">,</span>
<span class="s2">&quot;roi_h_6&quot;</span><span class="p">:</span> <span class="mi">540</span><span class="p">,</span>
<span class="s2">&quot;factor_6&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
</pre></div>
</div>
<p>第6层为缩放层，对应的基本层为第4层。原图为1920x1080分辨率，所以第4层分辨率为960x540。 第6层中设置的ROI区域大小为960x540，为整个第4层，缩放系数为64 / (64 + 32) = 2 / 3。 所以第6层图像的大小为 640 x 360</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">width_6</span> <span class="o">=</span> <span class="mi">960</span> <span class="n">x</span> <span class="mi">64</span> <span class="o">/</span> <span class="p">(</span><span class="mi">64</span> <span class="o">+</span> <span class="mi">32</span><span class="p">)</span> <span class="o">=</span> <span class="mi">640</span>
<span class="n">height_6</span> <span class="o">=</span> <span class="mi">540</span> <span class="n">x</span> <span class="mi">64</span> <span class="o">/</span> <span class="p">(</span><span class="mi">64</span> <span class="o">+</span> <span class="mi">32</span><span class="p">)</span> <span class="o">=</span> <span class="mi">360</span>
</pre></div>
</div>
<p>多路盒子智能解决方案金字塔配置的文件在：**solution_zoo/video_box/src/mediapipemanager目录下面的vpsmodule.cpp文件:</p>
<p>int VpsModule::Init 函数用于初始化vps，包括金字塔的属性。此函数内，所调用的HB_VPS_SetPymChnAttr接口则为配置金字塔属性接口，VPS_PYM_CHN_ATTR_S为金字塔属性结构体。</p>
<p>若需修改盒子的金字塔配置属性，可以参考修改此函数。</p>
<p>金字塔各层缩放比例，ROI区域的配置与此文件前述金字塔配置方法一致，此处不再详述。</p>
</div>
<div class="section" id="id2">
<h2>智能预测<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<div class="section" id="id3">
<h3>模型编译<a class="headerlink" href="#id3" title="永久链接至标题">¶</a></h3>
<p>检测模型的输入大小可以根据需要修改模型参数配置；</p>
<p>模型输入修改为NV12，也是可以通过浮点定点转换工具进行配置。</p>
<p>具体模型编译相关问题可以咨询地平线的AE。</p>
</div>
<div class="section" id="method">
<h3>模型预测Method的开发<a class="headerlink" href="#method" title="永久链接至标题">¶</a></h3>
<p>XStream-Framework推荐一个模型，使用两个Method完成，一个Method用于模型的预处理，调用bpu-predict的异步预测接口；一个Method用于获取异步预测的结果，进行模型后处理。这样设计的好处是让模型预测与模型后处理在多线程中异步执行，当输入任务足够时，整个pipeline吞吐大，bpu使用率高。</p>
<p>XStream-Framework对这两个Method做了封装，分别为DnnPredictMethod与DnnPostProcessMethod。对于每个模型，需要分别继承它们，重写前后处理接口。</p>
<ul class="simple">
<li>DnnPredictMethod： 完成模型的加载、输入与输出Tensor的分配、异步/同步bpu-predict接口调用。支持以Tensor方式预测，或者ROI方式预测。 继承者需要实现将Method的输入拷贝到输入Tensor，或者将Method的输入拷贝到金字塔与ROI数组中。</li>
<li>DnnPostProcessMethod: 调用HB_BPU_waitModelDone等待异步任务完成，然后进行后处理；或者对于同步任务，直接进行后处理。 继承者需要实现将模型的输出转成Method的输出的接口。</li>
</ul>
<p>xstream/framework/methods/DnnPredictMethod定义了模型预测Method的基类。</p>
<p>xstream/framework/methods/DnnPostProcessMethod定义了模型后处理Method的基类。</p>
<p>xstream/framework/methods/DnnAsyncData中定义了模型预测Method与模型后处理Method之间通信的数据结构。</p>
<div class="section" id="dnnasyncdata">
<h4>DnnAsyncData<a class="headerlink" href="#dnnasyncdata" title="永久链接至标题">¶</a></h4>
<p>XStream框架定义了DnnAsyncData，用于DnnPredictMethod与DnnPostProcessMethod之间传递的数据。DnnAsyncData的定义与说明如下：</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span> <span class="nl">DnnAsyncData</span> <span class="p">:</span> <span class="k">public</span> <span class="n">BaseData</span> <span class="p">{</span>
  <span class="c1">// 模型handle,解析结果时需要通过它获取模型的信息，比如shape、shift等</span>
  <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">BPUModelWrapper</span><span class="o">&gt;</span> <span class="n">dnn_model</span><span class="p">;</span>
  <span class="c1">// 输入tensor, 由DnnPostProcess进行资源释放</span>
  <span class="c1">// 最外层的vector,表示bpu任务的数量,与task_handle的维度一致,</span>
  <span class="c1">// 对于全图检测框类模型,维度应该为1，对于基于检测框做分类回归，</span>
  <span class="c1">// 则外层的vector数量与检测框数量一致；内部vector，表示模型需要输入tensor数量</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;&gt;</span> <span class="n">input_tensors</span><span class="p">;</span>
  <span class="c1">// 输出tensor,异步方式需要由DnnPostProcess进行资源释放，</span>
  <span class="c1">// 维度信息与input_tensors类似，内部vector维度，表示模型输出的output数量</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;&gt;</span> <span class="n">output_tensors</span><span class="p">;</span>
  <span class="c1">// 任务handle, 调用HB_BPU_waitModelDone接口需要，</span>
  <span class="c1">// 维度与input_tensors和output_tensors的外层维度一致</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TASK_HANDLE</span><span class="o">&gt;</span> <span class="n">task_handle</span><span class="p">;</span>
  <span class="c1">// 是否调用bpu-predict同步接口</span>
  <span class="kt">bool</span> <span class="n">dnn_is_sync</span><span class="p">;</span>

  <span class="c1">// 对于ROI类输入需要，需要在后处理中，valid_box与dnn_input_box在后续章节重点描述</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">valid_box</span><span class="p">;</span>
  <span class="c1">// pyramid + roi方式，后处理可能依赖ROI</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_BBOX</span><span class="o">&gt;</span> <span class="n">dnn_input_box</span><span class="p">;</span>

  <span class="c1">// 原始图像大小,后处理坐标映射可能需要</span>
  <span class="kt">int</span> <span class="n">src_image_width</span><span class="p">;</span>
  <span class="kt">int</span> <span class="n">src_image_height</span><span class="p">;</span>

  <span class="kt">void</span> <span class="o">*</span><span class="n">reserved</span><span class="p">;</span>  <span class="c1">// 保留字段,用于扩展</span>
<span class="p">};</span>
</pre></div>
</div>
</div>
<div class="section" id="dnnpredictmethod">
<h4>DnnPredictMethod<a class="headerlink" href="#dnnpredictmethod" title="永久链接至标题">¶</a></h4>
<p>DnnPredictMethod的接口说明如下,通过提供模型预处理接口，赋能其他模型完成模型的集成。</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DnnPredictMethod</span> <span class="o">:</span> <span class="k">public</span> <span class="n">Method</span> <span class="p">{</span>
 <span class="k">public</span><span class="o">:</span>
  <span class="n">DnnPredictMethod</span><span class="p">();</span>
  <span class="k">virtual</span> <span class="o">~</span><span class="n">DnnPredictMethod</span><span class="p">();</span>
  <span class="c1">// 读取配置文件，加载模型</span>
  <span class="c1">// DnnPredictMethod::Init中提供了几个配置字段，继承类可以重写Init接口，</span>
  <span class="c1">// 扩展配置，建议派生类Init接口中调用DnnPredictMethod::Init</span>
  <span class="c1">// 完成基础参数的读写以及模型加载工作。</span>
  <span class="kt">int</span> <span class="nf">Init</span><span class="p">(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="o">&amp;</span><span class="n">cfg_path</span><span class="p">)</span> <span class="k">override</span><span class="p">;</span>
  <span class="kt">void</span> <span class="nf">Finalize</span><span class="p">()</span> <span class="k">override</span><span class="p">;</span>

  <span class="c1">// 主逻辑，完全复用，派生类不需要再实现DoProcess;</span>
  <span class="c1">// 继承者大部分情况不需要重写DoProcess接口，DoProcess接口内部</span>
  <span class="c1">// 会调用虚函数PrepareInputData接口，完成模型预处理工作;</span>
  <span class="c1">// DoProcess接口返回DnnAsyncData这个数据结构对象，</span>
  <span class="c1">// DnnAsyncData这个结构在XStream框架中定义，</span>
  <span class="c1">// 用于将模型的相关信息、bpu任务信息传递给模型模型后处理模块</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;&gt;</span> <span class="n">DoProcess</span><span class="p">(</span>
      <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;&gt;</span> <span class="o">&amp;</span><span class="n">input</span><span class="p">,</span>
      <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">xstream</span><span class="o">::</span><span class="n">InputParamPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">param</span><span class="p">)</span> <span class="k">override</span><span class="p">;</span>

 <span class="k">public</span><span class="o">:</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">model_path_</span><span class="p">;</span>  <span class="c1">// 模型文件，Init()时从配置文件读取</span>

  <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">BPUModelWrapper</span><span class="o">&gt;</span> <span class="n">dnn_model_</span><span class="p">;</span>
  <span class="c1">// DNN预测结构方式，默认异步,Init()时从配置文件读取</span>
  <span class="kt">bool</span> <span class="n">dnn_is_sync_</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
  <span class="c1">// 是否是ROI方式,根据它实现不同的PrepareInputData接口，</span>
  <span class="c1">// 默认非roi输入,Init()时从配置文件读取</span>
  <span class="kt">bool</span> <span class="n">dnn_run_with_roi_</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>  
  <span class="c1">// 是否开启group模式，Init()时从配置文件读取</span>
  <span class="kt">bool</span> <span class="n">dnn_model_group_</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
  <span class="c1">// 运行的控制信息,主要设置模型运行的core_id，Init()时从配置文件读取</span>
  <span class="n">BPU_RUN_CTRL_S</span> <span class="n">dnn_ctrl_</span><span class="p">;</span>
  <span class="c1">// 原图的宽，Init()时从配置文件读取</span>
  <span class="kt">int</span> <span class="n">src_image_witdh_</span><span class="p">;</span>
  <span class="c1">// 原图的高，Init()时从配置文件读取</span>
  <span class="kt">int</span> <span class="n">src_image_height_</span><span class="p">;</span>

  <span class="c1">// 根据加载的模型，申请模型输入InputTensor大小，</span>
  <span class="kt">int</span> <span class="nf">AllocInputTensor</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">);</span>
  <span class="c1">// 根据加载的模型，申请模型输出OutputTensor大小</span>
  <span class="kt">int</span> <span class="nf">AllocOutputTensor</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">output_tensors</span><span class="p">);</span>
  <span class="c1">// 释放InputTensor/OutputTensor</span>
  <span class="kt">void</span> <span class="nf">FreeTensor</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">tensors</span><span class="p">);</span>

  <span class="c1">// 派生类需要实现</span>
  <span class="c1">// PrepareInputData内部需要根据一帧图像目标数量，</span>
  <span class="c1">// 多次调用AllocInputTensor分配空间.</span>
  <span class="c1">// PrepareInputData接口内部需要调用</span>
  <span class="c1">// AllocInputTensor/AllocOutputTensor，完成输入与输出的Tensor分配</span>
  <span class="c1">// IN: input, param; 对应workflow配置的该Method的输入，</span>
  <span class="c1">// 正常情况输入都是图片，不排除会有多个输入，比如图像+检测框。param基本不会用，可以不关注</span>
  <span class="c1">// OUT: input_tensors: PrepareInputData接口需要将预处理后的结果，填充到input_tensors中</span>
  <span class="c1">// OUT: output_tensors:PrepareInputData接口内部主要需要申请输出空间</span>
  <span class="c1">// 返回码：0，成功；否则失败；</span>
  <span class="k">virtual</span> <span class="kt">int</span> <span class="nf">PrepareInputData</span><span class="p">(</span>
      <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">input</span><span class="p">,</span>
      <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">InputParamPtr</span><span class="o">&gt;</span> <span class="n">param</span><span class="p">,</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;&gt;</span> <span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">,</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;&gt;</span> <span class="o">&amp;</span><span class="n">output_tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// 派生类需要实现，两个PrepareInputData，根据是否ROI，二选一实现即可。</span>
  <span class="c1">// 该模式是特殊用法，只支持对所有的ROI打包一起，</span>
  <span class="c1">// 调用一次预测接口，提高预测速度.</span>
  <span class="c1">// 模型必须是NV12输入，模型的预处理过程必须是根据roi检测框在原图抠图NV12，</span>
  <span class="c1">// 缩放到模型输入大小。其他预处理方式均不适用！</span>
  <span class="c1">// PrepareInputData接口内部需要调用AllocInputTensor/AllocOutputTensor，</span>
  <span class="c1">// 完成输入与输出的Tensor分配.</span>
  <span class="c1">// IN: input, param; 对应workflow配置的该Method的输入，</span>
  <span class="c1">// 正常情况都是图像+检测框两个输入。param基本不会用，可以不关注</span>
  <span class="c1">// OUT: pyramid: 将input中的图像解析出来，赋值到</span>
  <span class="c1">// hobot::vision::PymImageFrame，用于 调用bpu-predict接口。</span>
  <span class="c1">// OUT: input_bbox: 原图分辨率，ROI坐标框，预测需要.</span>
  <span class="c1">// OUT: valid_box，相对应input中检测框，每个input中的检测框是否送入bpu运算的标志，</span>
  <span class="c1">// 后处理模块需要.</span>
  <span class="c1">// OUT: output_tensors:PrepareInputData接口内部主要需要申请输出空间.</span>
  <span class="c1">// 返回码：0，成功；否则失败</span>
  <span class="k">virtual</span> <span class="kt">int</span> <span class="nf">PrepareInputData</span><span class="p">(</span>
      <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">input</span><span class="p">,</span>
      <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">InputParamPtr</span><span class="o">&gt;</span> <span class="n">param</span><span class="p">,</span>
      <span class="n">hobot</span><span class="o">::</span><span class="n">vision</span><span class="o">::</span><span class="n">PymImageFrame</span> <span class="o">&amp;</span><span class="n">pyramid</span><span class="p">,</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_BBOX</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">input_bbox</span><span class="p">,</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">valid_box</span><span class="p">,</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">output_tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="c1">// 用于获取原图分辨率的配置，后处理可能需要。</span>
  <span class="c1">// 建议将原图大小配置在配置文件中，Init的时候获取大小，</span>
  <span class="c1">// GetSrcImageSize的地方直接返回，</span>
  <span class="c1">// 若程序支持多分辨率输入，</span>
  <span class="c1">// GetSrcImageSize则可以运行时根据输入返回原图的大小</span>
  <span class="k">virtual</span> <span class="kt">int</span> <span class="nf">GetSrcImageSize</span><span class="p">(</span>
      <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">input</span><span class="p">,</span>
      <span class="kt">int</span> <span class="o">&amp;</span><span class="n">src_image_height</span><span class="p">,</span>
      <span class="kt">int</span> <span class="o">&amp;</span><span class="n">src_image_width</span><span class="p">);</span>
<span class="p">};</span>
</pre></div>
</div>
<p>DnnPredictMethod 支持的配置参数如下：</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="nt">&quot;model_file_path&quot;</span><span class="p">:</span> <span class="s2">&quot;parth to hbm/bin&quot;</span><span class="p">,</span>
  <span class="nt">&quot;dnn_is_sync&quot;</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
  <span class="nt">&quot;dnn_run_with_roi&quot;</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
  <span class="nt">&quot;dnn_model_group&quot;</span><span class="p">:</span> <span class="kc">false</span><span class="p">,</span>
  <span class="nt">&quot;dnn_model_group_id&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
  <span class="nt">&quot;core_id&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
  <span class="nt">&quot;src_image_witdh&quot;</span><span class="p">:</span> <span class="mi">1920</span><span class="p">,</span>
  <span class="nt">&quot;src_image_height&quot;</span><span class="p">:</span> <span class="mi">1080</span><span class="p">,</span>
  <span class="nt">&quot;others&quot;</span><span class="p">:</span> <span class="s2">&quot;inheritor can add other field&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>配置相关的说明：</p>
<ul class="simple">
<li>model_file_path: 模型hbm/bin文件路径，建议使用绝对路径</li>
<li>dnn_is_sync：使用bpu-predict同步方式与否，true表示同步方式，false为异步方式，建议为异步方式</li>
<li>dnn_run_with_roi：是否上ROI输入类型，true表示ROI输入。ROI输入方式表示BpuPredictMethod的内部实现会调用HB_BPU_runModelWithBbox完成预测，继承者需要实现PrepareInputData(for Rio)这个接口。非ROI方式输入，表示BpuPredictMethod的内部实现会调用HB_BPU_runModel完成预测，继承者需要实现PrepareInputData(for tensor)这个接口。</li>
<li>dnn_model_group：表示是否开启了group方式。对于开启model group方式，则需要设置一个group_id。注意：DnnPredictMethod本身不负责model group的创建，即DnnPredictMethod实现中不会调用HB_BPU_createGroup、HB_BPU_setGroupProportion、HB_BPU_deleteGroup等接口，只有可能调用HB_BPU_setModelGroup。</li>
<li>dnn_model_group_id： group模式，该模型的group id。</li>
</ul>
<p>进一步看下DnnPredictMethod::DoProcess的实现，大致可以了解模型预测的工作。</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;&gt;</span> <span class="n">DnnPredictMethod</span><span class="o">::</span><span class="n">DoProcess</span><span class="p">(</span>
    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;&gt;</span> <span class="o">&amp;</span><span class="n">input</span><span class="p">,</span>
    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">xstream</span><span class="o">::</span><span class="n">InputParamPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">param</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// 输出的batch数量与输入batch数量一致，当前batch均为1，即input.size() 与</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;&gt;</span> <span class="n">output</span><span class="p">;</span>
  <span class="n">output</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">input</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>  <span class="c1">// frame_size</span>

  <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">input</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">frame_input</span> <span class="o">=</span> <span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">frame_output</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="c1">// 创建BpuAsyncData，用于传递给DnnPostProcessMethod</span>
    <span class="k">auto</span> <span class="n">dnn_result</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">DnnAsyncData</span><span class="o">&gt;</span><span class="p">();</span>
    <span class="n">frame_output</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
    <span class="n">frame_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">dnn_result</span><span class="p">;</span>

    <span class="c1">// bpu 任务句柄</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TASK_HANDLE</span><span class="o">&gt;</span> <span class="n">task_handle</span><span class="p">;</span>

    <span class="c1">// 本次预测任务返回码，若添加任务失败，则DnnAsyncData中不需传递相关变量</span>
    <span class="kt">int</span> <span class="n">ret</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">dnn_run_with_roi_</span><span class="p">)</span> <span class="p">{</span>
      <span class="c1">// ROI方式：模型输入为ROI抠图得到的NV12图像，通过ROI方式，进行batch处理</span>
      <span class="n">task_handle</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
      <span class="c1">// 输入一个金字塔， 加上一系列ROI</span>
      <span class="c1">// 预测库bpu-predict内部根据金字塔每层大小以及ROI，自动完成抠图，缩放到模型输入大小</span>
      <span class="c1">// ROI输入方式，调用HB_BPU_runModelWithBbox进行预测，需要准备金字塔与ROI</span>
      <span class="n">hobot</span><span class="o">::</span><span class="n">vision</span><span class="o">::</span><span class="n">PymImageFrame</span> <span class="n">pyramid</span><span class="p">;</span>  <span class="c1">// get from frame_input</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_BBOX</span><span class="o">&gt;</span> <span class="n">input_box</span><span class="p">;</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">valid_box</span><span class="p">;</span>  <span class="c1">// 大小和Method输入的检测框一样，框是否有效</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;</span> <span class="n">output_tensor</span><span class="p">;</span>

      <span class="c1">// 调用派生类实现的模型预处理接口，获得图像金字塔、</span>
      <span class="c1">// 输入检测框等等。主要图像金字塔的资源释放完全由外部控制</span>
      <span class="n">ret</span> <span class="o">=</span> <span class="n">PrepareInputData</span><span class="p">(</span><span class="n">frame_input</span><span class="p">,</span> <span class="n">param</span><span class="p">,</span> <span class="n">pyramid</span><span class="p">,</span>
                             <span class="n">input_box</span><span class="p">,</span> <span class="n">valid_box</span><span class="p">,</span> <span class="n">output_tensor</span><span class="p">);</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">;</span>
      <span class="p">}</span>

      <span class="kt">int</span> <span class="n">resizable_cnt</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
      <span class="c1">// 调用BPU-Predict接口完成预测</span>
      <span class="n">bpu_predict_x3</span><span class="o">::</span><span class="n">PyramidResult</span> <span class="n">bpu_predict_pyramid</span><span class="p">;</span>
      <span class="n">Convert</span><span class="p">(</span><span class="n">pyramid</span><span class="p">,</span> <span class="n">bpu_predict_pyramid</span><span class="p">);</span>  <span class="c1">// 内部接口，可以不关注</span>
      <span class="c1">// 调用HB_BPU_runModelWithBbox进行模型预测</span>
      <span class="n">ret</span> <span class="o">=</span> <span class="n">HB_BPU_runModelWithBbox</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dnn_model_</span><span class="o">-&gt;</span><span class="n">bpu_model</span><span class="p">,</span>
          <span class="k">static_cast</span><span class="o">&lt;</span><span class="n">BPU_CAMERA_BUFFER</span><span class="o">&gt;</span><span class="p">(</span><span class="o">&amp;</span><span class="n">bpu_predict_pyramid</span><span class="p">.</span><span class="n">result_info</span><span class="p">),</span>
          <span class="n">input_box</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">input_box</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span>
          <span class="n">output_tensor</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">output_tensor</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span>
          <span class="o">&amp;</span><span class="n">dnn_ctrl_</span><span class="p">,</span> <span class="n">dnn_is_sync_</span><span class="p">,</span>
          <span class="o">&amp;</span><span class="n">resizable_cnt</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">task_handle</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// 释放output_tensor,task_handle</span>
        <span class="n">FreeTensor</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">);</span>
        <span class="n">HB_BPU_releaseTask</span><span class="p">(</span><span class="o">&amp;</span><span class="n">task_handle</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
        <span class="n">task_handle</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">;</span>
      <span class="p">}</span>
      <span class="c1">// 这部分逻辑，解决pyramid选层失败，导致roi未送入模型，避免出现bpu结果与输入roi错位的问题</span>
      <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">bpu_box_idx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">valid_box</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">valid_box</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="p">{</span>
          <span class="n">valid_box</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_box</span><span class="p">[</span><span class="n">bpu_box_idx</span><span class="p">].</span><span class="n">resizable</span><span class="p">;</span>
          <span class="n">bpu_box_idx</span><span class="o">++</span><span class="p">;</span>
        <span class="p">}</span>
      <span class="p">}</span>
      <span class="c1">// 赋值DnnAsyncData,roi方式不需要input_tensors</span>
      <span class="n">dnn_result</span><span class="o">-&gt;</span><span class="n">dnn_model</span> <span class="o">=</span> <span class="n">dnn_model_</span><span class="p">;</span>
      <span class="n">dnn_result</span><span class="o">-&gt;</span><span class="n">output_tensors</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">);</span>
      <span class="n">dnn_result</span><span class="o">-&gt;</span><span class="n">task_handle</span> <span class="o">=</span> <span class="n">task_handle</span><span class="p">;</span>
      <span class="n">dnn_result</span><span class="o">-&gt;</span><span class="n">valid_box</span> <span class="o">=</span> <span class="n">valid_box</span><span class="p">;</span>
      <span class="n">dnn_result</span><span class="o">-&gt;</span><span class="n">dnn_input_box</span> <span class="o">=</span> <span class="n">input_box</span><span class="p">;</span>
      <span class="n">dnn_result</span><span class="o">-&gt;</span><span class="n">dnn_is_sync</span> <span class="o">=</span> <span class="n">dnn_is_sync_</span><span class="p">;</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
      <span class="c1">// Tensor输入方式，调用HB_BPU_runModel完成预测，需要创建输入与输出tensor</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;&gt;</span> <span class="n">input_tensor</span><span class="p">;</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;&gt;</span> <span class="n">output_tensor</span><span class="p">;</span>
      <span class="c1">// 调用派生类实现，获得原图的宽与高</span>
      <span class="n">GetSrcImageSize</span><span class="p">(</span><span class="n">frame_input</span><span class="p">,</span> <span class="n">dnn_result</span><span class="o">-&gt;</span><span class="n">src_image_height</span><span class="p">,</span>
                               <span class="n">dnn_result</span><span class="o">-&gt;</span><span class="n">src_image_width</span><span class="p">);</span>

      <span class="c1">// 调用派生类的实现，进行模型预处理，得到模型预测需要的input_tensor</span>
      <span class="n">ret</span> <span class="o">=</span> <span class="n">PrepareInputData</span><span class="p">(</span><span class="n">frame_input</span><span class="p">,</span> <span class="n">param</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">output_tensor</span><span class="p">);</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">;</span>
      <span class="p">}</span>
      <span class="n">task_handle</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>
      <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">input_tensor</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// 申请input_tensor或output_tensor失败</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">input_tensor</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span> <span class="o">||</span> <span class="n">output_tensor</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
          <span class="k">continue</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="c1">// 调用bpu-predict接口完成预测</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">HB_BPU_runModel</span><span class="p">(</span><span class="o">&amp;</span><span class="n">dnn_model_</span><span class="o">-&gt;</span><span class="n">bpu_model</span><span class="p">,</span>
                              <span class="n">input_tensor</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">data</span><span class="p">(),</span> <span class="n">input_tensor</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">size</span><span class="p">(),</span>
                              <span class="n">output_tensor</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">data</span><span class="p">(),</span> <span class="n">output_tensor</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">size</span><span class="p">(),</span>
                              <span class="o">&amp;</span><span class="n">dnn_ctrl_</span><span class="p">,</span> <span class="n">dnn_is_sync_</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">task_handle</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
          <span class="c1">// 释放input_tensor,output_tensor,task_handle</span>
          <span class="c1">// DnnPostProcessMethod中可通过这些字段判断是否需要后处理解析</span>
          <span class="n">FreeTensor</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
          <span class="n">FreeTensor</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
          <span class="n">HB_BPU_releaseTask</span><span class="p">(</span><span class="o">&amp;</span><span class="n">task_handle</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
          <span class="n">task_handle</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
        <span class="p">}</span>
      <span class="p">}</span>

      <span class="c1">// 赋值BpuAsyncData</span>
      <span class="n">dnn_result</span><span class="o">-&gt;</span><span class="n">dnn_model</span> <span class="o">=</span> <span class="n">dnn_model_</span><span class="p">;</span>
      <span class="n">dnn_result</span><span class="o">-&gt;</span><span class="n">input_tensors</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="p">;</span>
      <span class="n">dnn_result</span><span class="o">-&gt;</span><span class="n">output_tensors</span> <span class="o">=</span> <span class="n">output_tensor</span><span class="p">;</span>
      <span class="n">dnn_result</span><span class="o">-&gt;</span><span class="n">task_handle</span> <span class="o">=</span> <span class="n">task_handle</span><span class="p">;</span>
      <span class="n">dnn_result</span><span class="o">-&gt;</span><span class="n">dnn_is_sync</span> <span class="o">=</span> <span class="n">dnn_is_sync_</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="k">return</span> <span class="n">output</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>接下来重点解释下模型预处理这个接口的含义。这两个接口，用于不同的模型，实现其中一个即可。</p>
<p>ROI方式使用限制很多，在后续章节会有补充的说明。大部分模型，均建议使用非ROI方式。</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span>  <span class="k">virtual</span> <span class="kt">int</span> <span class="nf">PrepareInputData</span><span class="p">(</span>
      <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">input</span><span class="p">,</span>
      <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">InputParamPtr</span><span class="o">&gt;</span> <span class="n">param</span><span class="p">,</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;&gt;</span> <span class="o">&amp;</span><span class="n">input_tensors</span><span class="p">,</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;&gt;</span> <span class="o">&amp;</span><span class="n">output_tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="cm">/*</span>
<span class="cm">      接口返回0表示成功，其他值失败。</span>
<span class="cm">      input为预测Method一帧图像的输入，在workflow json文件中配置，比如输入的是图像；</span>
<span class="cm">      或者输入的是图像+人体检测框；或者输入的是图像+人体关键点等等。</span>

<span class="cm">      param参数主要是使用XStream框架完成参数动态更新的需求。若无该需求，可以不关注它</span>

<span class="cm">      input_tensors,是该接口的输出。每个模型可能有多个输入，每个输入用一个BPU_TENSOR_S表示。</span>
<span class="cm">      所以std::vector&lt;BPU_TENSOR_S&gt;表示的是模型的一次输入。</span>
<span class="cm">      对于全图检测，一帧图像可能只需要一次预测就可以。但是对于基于检测框做的一些分类任务，一帧图像</span>
<span class="cm">      可能含有多个检测框，每个检测框需要单独进行预测，那么这种场景，一帧图像就需要对每个检测框分别</span>
<span class="cm">      预处理，得到每个检测框的输入，所以input_tensors有个外围的vector。input_tensors里面对应</span>
<span class="cm">      每个目标的输入，顺序与input中传进来的检测框是一致的。</span>

<span class="cm">      output_tensors，是该模型的输出，PrepareInputData中主要根据模型的输出数量分配模型一次预测</span>
<span class="cm">      的输出tensor空间std::vector&lt;BPU_TENSOR_S&gt;。对应一帧中有多个检测框，则会对每个检测框的预测</span>
<span class="cm">      单独分配输出空间。</span>
<span class="cm">    */</span>
  <span class="p">}</span>

  <span class="k">virtual</span> <span class="kt">int</span> <span class="nf">PrepareInputData</span><span class="p">(</span>
      <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">input</span><span class="p">,</span>
      <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">InputParamPtr</span><span class="o">&gt;</span> <span class="n">param</span><span class="p">,</span>
      <span class="n">hobot</span><span class="o">::</span><span class="n">vision</span><span class="o">::</span><span class="n">PymImageFrame</span> <span class="o">&amp;</span><span class="n">pyramid</span><span class="p">,</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_BBOX</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">input_bbox</span><span class="p">,</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">valid_box</span><span class="p">,</span>
      <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">output_tensors</span><span class="p">)</span> <span class="p">{</span>
    <span class="cm">/*</span>
<span class="cm">      接口返回0表示成功，其他值失败。</span>
<span class="cm">      input为预测Method一帧图像的输入，在workflow json文件中配置，该种模式输入一般是</span>
<span class="cm">      图像+检测框。</span>

<span class="cm">      param参数主要是使用XStream框架完成参数动态更新的需求。若无该需求，可以不关注它。</span>

<span class="cm">      pyramid为输出参数，用于从input中，获得图像金字塔信息，然后将金字塔结果赋值到pyramid中。</span>

<span class="cm">      input_bbox为需要送入模型分析的检测框，和input中传入的检测框区别是input中可能存在一些检测框，</span>
<span class="cm">      其数据的状态为无效或者被过滤，则input_bbox中不应该包含这些检测框。</span>

<span class="cm">      valid_box主要用于和input中传入的检测框映射，模型后处理需要，模型后处理需要这个valid_box,</span>
<span class="cm">      将bpu的预测结果与具体的input的检测框匹配。</span>

<span class="cm">      output_tensors, 目前该参数与上一个接口有些诧异，主要是由BPU-PREDICT接口差异导致。</span>
<span class="cm">      为理解方便，可以假设ROI模式，模型的输出只有一个；对于输出有多个的，当前的接口不是很好解释，</span>
<span class="cm">      不建议使用ROI模式。鉴于此，该接口后续可能伴随着BPU-PREDICT接口的升级而发生改变。</span>
<span class="cm">    */</span>
  <span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="dnnpostprocessmethod">
<h4>DnnPostProcessMethod<a class="headerlink" href="#dnnpostprocessmethod" title="永久链接至标题">¶</a></h4>
<p>DnnPostProcessMethod的作用是对bpu的预测结果进行模型后处理，解析成物理有意义的数据结构。DnnPostProcessMethod通过提供模型后处理接口，赋能其他模型的集成。</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">DnnPostProcessMethod</span> <span class="o">:</span> <span class="k">public</span> <span class="n">Method</span> <span class="p">{</span>
 <span class="k">public</span><span class="o">:</span>
  <span class="n">DnnPostProcessMethod</span><span class="p">()</span> <span class="p">{}</span>
  <span class="k">virtual</span> <span class="o">~</span><span class="n">DnnPostProcessMethod</span><span class="p">()</span> <span class="p">{}</span>

  <span class="c1">// 内部加载了配置文件，生成了json对象config_,派生类可以基于该对象解析派生类需要的字段</span>
  <span class="kt">int</span> <span class="n">Init</span><span class="p">(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="o">&amp;</span><span class="n">cfg_path</span><span class="p">)</span> <span class="k">override</span><span class="p">;</span>
  <span class="kt">void</span> <span class="nf">Finalize</span><span class="p">()</span> <span class="k">override</span><span class="p">;</span>

  <span class="c1">// 主逻辑，完全复用，派生类不需要再实现DoProcess</span>
  <span class="c1">// 继承者大部分情况不需要重写DoProcess接口，DoProcess接口内部</span>
  <span class="c1">// 会调用HB_BPU_waitModelDone获得BPU的预测结果，然后会调用</span>
  <span class="c1">// 派生类实现的ParseDnnResult结果完成模型后处理的解析</span>
  <span class="c1">// 最后会释放模型输入与输出tensor</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;&gt;</span> <span class="n">DoProcess</span><span class="p">(</span>
      <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;&gt;</span> <span class="o">&amp;</span><span class="n">input</span><span class="p">,</span>
      <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">xstream</span><span class="o">::</span><span class="n">InputParamPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">param</span><span class="p">)</span> <span class="k">override</span><span class="p">;</span>

 <span class="k">public</span><span class="o">:</span>
  <span class="c1">// 释放InputTensor/OutputTensor</span>
  <span class="kt">void</span> <span class="n">FreeTensor</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BPU_TENSOR_S</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">tensors</span><span class="p">);</span>

  <span class="c1">// 派生类需要实现</span>
  <span class="c1">// 完成模型的后处理，以及转换成Method输出格式;不需考虑tensor的释放</span>
  <span class="c1">// IN: dnn_result. OUT: frame_result</span>
  <span class="k">virtual</span> <span class="kt">int</span> <span class="nf">ParseDnnResult</span><span class="p">(</span><span class="n">DnnAsyncData</span> <span class="o">&amp;</span><span class="n">dnn_result</span><span class="p">,</span>
                             <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">frame_result</span><span class="p">);</span>
<span class="p">};</span>
</pre></div>
</div>
<p>DnnPostProcessMethod的DoProcess比较简单，如下所述：</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;&gt;</span> <span class="n">DnnPostProcessMethod</span><span class="o">::</span><span class="n">DoProcess</span><span class="p">(</span>
    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;&gt;</span> <span class="o">&amp;</span><span class="n">input</span><span class="p">,</span>
    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">xstream</span><span class="o">::</span><span class="n">InputParamPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">param</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// batch帧，当前batch均为1</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;&gt;</span> <span class="n">output</span><span class="p">;</span>
  <span class="n">output</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">input</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>

  <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">input</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">frame_input</span> <span class="o">=</span> <span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">frame_output</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>

    <span class="c1">// DnnPostProcessMethod的输入只有一个，输入数据就是DnnAsyncData</span>
    <span class="n">HOBOT_CHECK</span><span class="p">(</span><span class="n">frame_input</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>  <span class="o">&lt;&lt;</span> <span class="s">&quot;only support DnnAsyncData&quot;</span><span class="p">;</span>
    <span class="k">auto</span> <span class="n">dnn_async_data</span> <span class="o">=</span>
        <span class="n">std</span><span class="o">::</span><span class="n">static_pointer_cast</span><span class="o">&lt;</span><span class="n">DnnAsyncData</span><span class="o">&gt;</span><span class="p">(</span><span class="n">frame_input</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>

    <span class="c1">// 调用HB_BPU_waitModelDone接口，等待bpu异步任务完成</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">dnn_async_data</span><span class="o">-&gt;</span><span class="n">dnn_is_sync</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">dnn_async_data</span><span class="o">-&gt;</span><span class="n">task_handle</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">BPU_TASK_HANDLE</span> <span class="o">&amp;</span><span class="n">task_handle</span> <span class="o">=</span> <span class="n">dnn_async_data</span><span class="o">-&gt;</span><span class="n">task_handle</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">task_handle</span> <span class="o">==</span> <span class="k">nullptr</span><span class="p">)</span> <span class="k">continue</span><span class="p">;</span>
        <span class="n">HB_BPU_waitModelDone</span><span class="p">(</span><span class="o">&amp;</span><span class="n">task_handle</span><span class="p">);</span>
        <span class="n">HB_BPU_releaseTask</span><span class="p">(</span><span class="o">&amp;</span><span class="n">task_handle</span><span class="p">);</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="c1">// 调用派生类的接口，完成模型后处理，将结果转换成Method的输出格式‘</span>
    <span class="n">ParseDnnResult</span><span class="p">(</span><span class="o">*</span><span class="n">dnn_async_data</span><span class="p">,</span> <span class="n">frame_output</span><span class="p">);</span>
    <span class="c1">// 释放输入与输出Tensor</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">dnn_async_data</span><span class="o">-&gt;</span><span class="n">input_tensors</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">dnn_async_data</span><span class="o">-&gt;</span><span class="n">input_tensors</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
        <span class="n">FreeTensor</span><span class="p">(</span><span class="n">dnn_async_data</span><span class="o">-&gt;</span><span class="n">input_tensors</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">dnn_async_data</span><span class="o">-&gt;</span><span class="n">output_tensors</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">dnn_async_data</span><span class="o">-&gt;</span><span class="n">output_tensors</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
        <span class="n">FreeTensor</span><span class="p">(</span><span class="n">dnn_async_data</span><span class="o">-&gt;</span><span class="n">output_tensors</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="k">return</span> <span class="n">output</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>下面说明下后处理接口，接口描述也很简单</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span> <span class="n">ParseDnnResult</span><span class="p">(</span><span class="n">DnnAsyncData</span> <span class="o">&amp;</span><span class="n">dnn_result</span><span class="p">,</span>
                             <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;</span> <span class="o">&amp;</span><span class="n">frame_result</span><span class="p">)</span>
<span class="cm">/*</span>
<span class="cm">  接口返回0表示成功，其他值失败。</span>
<span class="cm">  dnn_result为模型预处理与模型后处理传递的数据，调用ParseDnnResult时，说明模型输出</span>
<span class="cm">  的Tensor已经赋值。</span>

<span class="cm">  frame_result为该Methd一帧图像对应的输出。</span>
<span class="cm">*/</span>
</pre></div>
</div>
</div>
<div class="section" id="roi">
<h4>ROI方式进一步解释<a class="headerlink" href="#roi" title="永久链接至标题">¶</a></h4>
<p>DnnPredictMethod中ROI方式对应的预处理接口中input_bbox、valid_box以及method输入检测框的关系，用下面一个示例说明。</p>
<p><img alt="valid_box" src="../../_images/valid_box.png" /></p>
<p>这里的示例，预测Method输入5个BOX，其中BOX3 可能被之前的Method模块处理，标志为过滤状态，所以不需要送入到模型中预测。</p>
<p>因此派生类在实现PrepareInputData接口的时候，应该将valid_box设置为[1,1,0,1,1]。valid_box大小与Method输入的检测框大小一致，而把input_bbox设置为[BOX1, BOX2, BOX4, BOX5],表示希望对这4个检测框做预测。</p>
<p>ROI方式，内部实现是基于地平线芯片中图像金字塔与硬件Resize模块完成图像抠图缩放，硬件Resize有缩放比例限制，导致不是所有的检测框，都可以缩放到模型输入大小，所有我们预处理后，需要分析的4个检测框，可能不能完全得到预测，比如BOX2。</p>
<p>当DnnPredictMethod::DoProcess接口内部调用完BPU-PREDICT的HB_BPU_runModelWithBbox接口，就可以知道哪些检测框不符合金字塔选层缩放规则，所以DnnPredictMethod::DoProcess内部会更新valid_box的状态，设置为[1,0,0,1,1]，同时送入bpu的任务其实只有BOX1， BOX4， BOX5。</p>
<p>这样当后处理Method得到模型的预测结果后，解析得到三个结果，再通过valid_box，就可以得知预测结果与哪个检测框匹配。</p>
</div>
<div class="section" id="id4">
<h4>模型集成的示例<a class="headerlink" href="#id4" title="永久链接至标题">¶</a></h4>
<p>待补充。计划放在XStream的tutorial中。</p>
</div>
</div>
</div>
<div class="section" id="id5">
<h2>效果展示<a class="headerlink" href="#id5" title="永久链接至标题">¶</a></h2>
<p>当我们将模型的前后处理均实现好后，可以尝试复用xproto/plugins/smartplugin，完成模型的预测，使用xproto/plugins/websocketplugin将图像与感知结果通过websocket方式发给web浏览器。</p>
<div class="section" id="customsmartmessage">
<h3>CustomSmartMessage<a class="headerlink" href="#customsmartmessage" title="永久链接至标题">¶</a></h3>
<p>xproto/plugins/smartplugin/smartplugin.h中定义了horizon::vision::xproto::smartplugin::CustomSmartMessage。</p>
<p>CustomSmartMessage为SmartPlugin内部调用xstream执行workflow得到的智能感知结果，用于推送到xproto消息总线。</p>
<p>当前CustomSmartMessage参杂着一些业务代码，但是不影响可扩展。后续CustomSmartMessage可能择机重构。</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#define TYPE_SMART_MESSAGE &quot;XPLUGIN_SMART_MESSAGE&quot;</span>

<span class="k">struct</span> <span class="nl">CustomSmartMessage</span> <span class="p">:</span> <span class="n">SmartMessage</span> <span class="p">{</span>
  <span class="k">explicit</span> <span class="n">CustomSmartMessage</span><span class="p">(</span>
    <span class="n">xstream</span><span class="o">::</span><span class="n">OutputDataPtr</span> <span class="n">out</span><span class="p">)</span> <span class="o">:</span> <span class="n">smart_result</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 消息类型。派生类需要换另外一个名字</span>
    <span class="n">type_</span> <span class="o">=</span> <span class="n">TYPE_SMART_MESSAGE</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="c1">// 序列化，可以先不关注该接口</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">Serialize</span><span class="p">()</span> <span class="k">override</span><span class="p">;</span>

  <span class="c1">// 序列化，发送给web展示端的图像，可能是基于原图做了缩放</span>
  <span class="c1">// 所以需要将对应的感知结果，缩放到web图的大小。</span>
  <span class="c1">// CustomSmartMessage的smart_result保存的都是原图分辨率下的坐标信息</span>
  <span class="c1">// 派生类需要重点实现该接口。</span>
  <span class="c1">// 该接口的实现依赖x3.proto。具体描述如下</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">Serialize</span><span class="p">(</span><span class="kt">int</span> <span class="n">ori_w</span><span class="p">,</span> <span class="kt">int</span> <span class="n">ori_h</span><span class="p">,</span> <span class="kt">int</span> <span class="n">dst_w</span><span class="p">,</span> <span class="kt">int</span> <span class="n">dst_h</span><span class="p">)</span> <span class="k">override</span><span class="p">;</span>
 <span class="k">protected</span><span class="o">:</span>
  <span class="n">xstream</span><span class="o">::</span><span class="n">OutputDataPtr</span> <span class="n">smart_result</span><span class="p">;</span>
<span class="p">};</span>
</pre></div>
</div>
<p>扩展方式：</p>
<p>1） 评估是否可以直接复用CustomSmartMessage，大概率是可以</p>
<p>2） 若必须扩展，则继承CustomSmartMessage，设置不同的type_类别，根据需要重写Serialize接口。</p>
</div>
<div class="section" id="x3-proto">
<h3>x3.proto<a class="headerlink" href="#x3-proto" title="永久链接至标题">¶</a></h3>
<p>上面提到CustomSmartMessage或者CustomSmartMessage的序列化接口Serialize，需要将感知结果通过proto-buf序列化成字符串。</p>
<p>AI-Express根据经验，整理了x3.proto，应付大部分场景。使用者可以直接复用。</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span>syntax = &quot;proto3&quot;;
package x3;
option optimize_for = LITE_RUNTIME;

/**
 * 字节数组
 * @type_ {1} 类型名称
 * @array_ {2} 字节数组
 */
message CharArray {
  string type_ = 1;
  bytes array_ = 2;
}

/**
 * Float 数组
 * @type_ {1} 类型名称
 * @value_ {2} 值
 */
message FloatArray {
  string type_ = 1;
  repeated float value_ = 2;
}

/**
 * Float 2维矩阵
 * @type_ {1} 类型名称
 * @arrays_ {2} float数组
 */
message FloatMatrix {
  string type_ = 1;
  repeated FloatArray arrays_ = 2;
}

/**
 * 坐标点
 * @x_ {1} x坐标
 * @y_ {2} y坐标
 * @score_ {3} 置信度
 */
message Point {
  float x_ = 1;
  float y_ = 2;
  float score_ = 3;
}

/**
 * 坐标点集合
 * @type_ {1} 类型名称
 * @points_ {2} 坐标点集合
 */
message Points {
  string type_ = 1;
  repeated Point points_ = 2;
}

/**
 * 检测框
 * @type_ {1} 类型名称
 * @top_left_ {2} 左上点
 * @bottom_right_ {3} 右下点
 */
message Box {
  string type_ = 1;
  Point top_left_ = 2;
  Point bottom_right_ = 3;
  float score = 4;
}

/**
 * 属性
 * @type_ {1} 类型名称，包括年龄、性别、眼镜、口罩、活体信息、车辆信息、非机动车信息,道路状况
 * @value_ {2} 值
 * @score_ {3} 置信度
 */
message Attributes {
  string type_ = 1;
  float value_ = 2;
  string value_string_ = 3;
  float score_ = 4;
}

/**
 *  图片信息
 * @buf_ {1} 图片二进制流
 * @buf_ {2} 图片类型，如：灰度图、YUV420、NV21、NV12、BGR、JPEG
 * @width_ {3} 图片宽度
 * @height_ {4} 图片高度
 */
message Image {
  bytes buf_ = 1;
  string type_ = 2;
  uint32 width_ = 3;
  uint32 height_ = 4;
}

/**
 * 智能帧跟踪目标信息
 * @type_ {1} 跟踪目标类型名称，如：人、车、动物、非机动车，可以随便设置一个string
 * @track_id_ {2} 跟踪目标ID号
 * @imgs_ {3} 抓拍图，不需要关注
 * @sub_targets_ {4} 子目标，暂时可以不关注
 * @boxes_ {5} 检测框集合，一个目标一般只有一个检测框
 * @attributes_  {6} 属性集合，如：年龄、性别等
 * @points_  {7} 多个坐标点集合，如：人脸关键点等
 * @float_arrays_  {8} Float点集合，若不需要可以不关注
 * @float_matrixs_  {9} Float矩阵集合，比如人体分割结果，若不需要可以不关注
 * @char_arrays_ {10} 字节数组集合，如加密后的特征，若不需要可以不关注
 */
message Target {
  string type_ = 1;
  uint64 track_id_ = 2;
  repeated Image imgs_ = 3;
  repeated Target sub_targets_ = 4;
  repeated Box boxes_ = 5;
  repeated Attributes attributes_ = 6;
  repeated Points points_ = 7;
  repeated FloatArray float_arrays_ = 8;
  repeated FloatMatrix float_matrixs_ = 9;
  repeated CharArray char_arrays_ = 10;

}

/**
 * 智能帧信息
 * @timestamp_ {1} 原视频帧的时间戳
 * @error_code_ {2} 错误码
 * @targets {3} 目标集合，若有感知结果，必须要设置
 */
message SmartFrameMessage {
  fixed64 timestamp_ = 1;
  uint32 error_code_ = 2;
  repeated Target targets_ = 3;
}

/**
 * X2 Protobuf: Last Result Message
 * @smart_msg_ {1} smart frame info，若有感知结果，必须要设置
 * @capture_msg_ {2} capture frame info，主要用于抓拍场景，可以先不关注
 * @Statistics_msg_ {3} statistics info， 统计信息，可以先不关注
 * @img_ {4} frame img info，必须要设置
 * @timestamp_ {5} timestamp
 */
message FrameMessage {
  SmartFrameMessage smart_msg_ = 1;
  CaptureFrameMessage capture_msg_ = 2;
  StatisticsMessage Statistics_msg_ = 3;
  Image img_ = 4;
  fixed64 timestamp_ = 5;
  uint64 sequence_id_ = 6;
}
</pre></div>
</div>
<p>具体序列化示例，可以参考CustomSmartMessage::Serialize(int ori_w, int ori_h, int dst_w, int dst_h)接口实现，或者示例soluton中的实现。</p>
</div>
<div class="section" id="smartplugin">
<h3>SmartPlugin<a class="headerlink" href="#smartplugin" title="永久链接至标题">¶</a></h3>
<p>xproto/plugins/smartplugin中定义了类horizon::vision::xproto::smartplugin::SmartPlugin。SmartPlugin内部会加载xstream workflow，订阅iotvioplugin产生的金字塔图像消息，送入xstream中进行预测，获得预测结果后，转换成感知结果，推送到xproto消息总线。</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SmartPlugin</span> <span class="o">:</span> <span class="k">public</span> <span class="n">XPluginAsync</span> <span class="p">{</span>
 <span class="k">public</span><span class="o">:</span>
  <span class="n">SmartPlugin</span><span class="p">()</span> <span class="o">=</span> <span class="k">default</span><span class="p">;</span>
  <span class="c1">// 派生类的构造函数需要调用</span>
  <span class="c1">// SmartPlugin::SmartPlugin(const std::string&amp; config_file)</span>
  <span class="k">explicit</span> <span class="nf">SmartPlugin</span><span class="p">(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span> <span class="n">config_file</span><span class="p">);</span>
  <span class="c1">// 下面几个接口，派生类可以不需要重写</span>
  <span class="o">~</span><span class="n">SmartPlugin</span><span class="p">()</span> <span class="o">=</span> <span class="k">default</span><span class="p">;</span>
  <span class="kt">int</span> <span class="nf">Init</span><span class="p">()</span> <span class="k">override</span><span class="p">;</span>
  <span class="kt">int</span> <span class="nf">DeInit</span><span class="p">()</span> <span class="k">override</span><span class="p">;</span>
  <span class="kt">int</span> <span class="nf">Start</span><span class="p">()</span> <span class="k">override</span><span class="p">;</span>
  <span class="kt">int</span> <span class="nf">Stop</span><span class="p">()</span> <span class="k">override</span><span class="p">;</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">desc</span><span class="p">()</span> <span class="k">const</span> <span class="p">{</span> <span class="k">return</span> <span class="s">&quot;SmartPlugin&quot;</span><span class="p">;</span> <span class="p">}</span>

 <span class="k">private</span><span class="o">:</span>
  <span class="c1">// 获取单路图像，workflow配置的图像输入节点名字</span>
  <span class="c1">// SmartPlugin派生类可以根据需要修改输入节点的名字</span>
  <span class="c1">// 但是必须保证该接口返回的图像输入节点名字和xstream json配置中一致</span>
  <span class="c1">// 派生类需要关注该接口，若workflow输入也定义为image，则可以不重写</span>
  <span class="k">virtual</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">GetWorkflowInputImageName</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">return</span> <span class="s">&quot;image&quot;</span><span class="p">;</span>  <span class="c1">// 当前沉淀的solution均使用image这个</span>
  <span class="p">}</span>

  <span class="c1">// 创建xproto框架下感知结果的消息对象</span>
  <span class="c1">// 感知结果消息对象必须是CustomSmartMessage或者集成自CustomSmartMessage</span>
  <span class="c1">// 输入参数xstream_out为xstream workflow执行完成，xstream回调返回的数据对象</span>
  <span class="c1">// 派生类需要关注该接口，若需要生成其他的消息，则需要重写该接口</span>
  <span class="k">virtual</span> <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">CustomSmartMessage</span><span class="o">&gt;</span>
  <span class="n">CreateSmartMessage</span><span class="p">(</span><span class="n">xstream</span><span class="o">::</span><span class="n">OutputDataPtr</span> <span class="n">xstream_out</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 当前沉淀的解决方案，默认为CustomSmartMessage对象</span>
    <span class="k">return</span> <span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">CustomSmartMessage</span><span class="o">&gt;</span><span class="p">(</span><span class="n">xstream_out</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
<p>由于iotvioplugin当前不支持扩展，产生的消息类型是固定的，所以对于SmartPlugin，未提供订阅图像消息的扩展接口。</p>
<p>使用SmartPlugin，需要关注的配置文件如下,主要是需要配置xstream的workflow配置文件。</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="nt">&quot;xstream_workflow_file&quot;</span><span class="p">:</span> <span class="s2">&quot;det_mot.json&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>扩展方式：</p>
<p>1）评估现有SmartPlugin，一般情况是可以复用。但是若需要发送的消息类型不是CustomSmartMessage，则必须要继承SmartPlugin</p>
<p>2）若继承SmartPlugin，则需要重写GetWorkflowInputImageName以及CreateSmartMessage这两个接口，构造函数中调用SmartPlugin::SmartPlugin(const std::string&amp; config_file)。派生类的实现使用XPLUGIN_REGISTER_MSG_TYPE注册下感知结果消息。其他接口不太需要关注。</p>
</div>
<div class="section" id="websocketplugin">
<h3>WebsocketPlugin<a class="headerlink" href="#websocketplugin" title="永久链接至标题">¶</a></h3>
<p>xproto/plugins/websocketplugin中定义了WebsocketPlugin。</p>
<p>WebsocketPlugin内部会从消息总线获取iotvioplugin发过来的图像消息，以及smartplugin发送过来的感知结果消息。</p>
<p>WebsocketPlugin内部会对图像进行jpg编码，同时调用感知结果消息的序列化接口进行序列化，再进行图像与感知结果的匹配，最后通过websocket发送给web前端。</p>
<p>WebsocketPlugin的定义如下：</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">WebsocketPlugin</span> <span class="o">:</span> <span class="k">public</span> <span class="n">xproto</span><span class="o">::</span><span class="n">XPluginAsync</span> <span class="p">{</span>
 <span class="k">public</span><span class="o">:</span>
  <span class="n">WebsocketPlugin</span><span class="p">()</span> <span class="o">=</span> <span class="k">delete</span><span class="p">;</span>
  <span class="c1">// 派生类构造的时候需要调用WebsocketPlugin::WebsocketPlugin(std::string config_path)</span>
  <span class="k">explicit</span> <span class="nf">WebsocketPlugin</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">config_path</span><span class="p">);</span>
  <span class="o">~</span><span class="n">WebsocketPlugin</span><span class="p">()</span> <span class="k">override</span><span class="p">;</span>
  <span class="c1">// 派生类对下面这几个接口均不需要重写</span>
  <span class="kt">int</span> <span class="nf">Init</span><span class="p">()</span> <span class="k">override</span><span class="p">;</span>
  <span class="kt">int</span> <span class="nf">Start</span><span class="p">()</span> <span class="k">override</span><span class="p">;</span>
  <span class="kt">int</span> <span class="nf">Stop</span><span class="p">()</span> <span class="k">override</span><span class="p">;</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">desc</span><span class="p">()</span> <span class="k">const</span> <span class="p">{</span> <span class="k">return</span> <span class="s">&quot;WebsocketPlugin&quot;</span><span class="p">;</span> <span class="p">}</span>

 <span class="k">private</span><span class="o">:</span>
  <span class="c1">// 这里需要与SmartPlugin产生的感知消息匹配</span>
  <span class="c1">// 一般情况，若SmartPlugin的派生类产生新的消息类型</span>
  <span class="c1">// (继承CustomSmartMessage),则需要新建类继承WebsocketPlugin，</span>
  <span class="c1">// 重写GetSmartMessageType接口</span>
  <span class="k">virtual</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">GetSmartMessageType</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">// 当前解决方案默认使用TYPE_SMART_MESSAGE</span>
    <span class="k">return</span> <span class="n">TYPE_SMART_MESSAGE</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
<p>WebsocketPlugin的配置信息如下：</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="nt">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">4</span>
<span class="p">}</span>
</pre></div>
</div>
<p>layer主要设置iotvioplugin产生的图像的哪一个基础层【0， 4， 8， 12， 16】之类，将该层图像编码成jpg，发送给web。</p>
<p>若layer不是第0层，则调用感知消息的Serialize(int ori_w, int ori_h, int dst_w, int dst_h)接口时，会将感知结果中的检测框与坐标点之类的结果，缩放到对应layer层分辨率上，确保发给web的图像与感知结果，分辨率空间是一致。</p>
<p>扩展方式：</p>
<p>1）若SmartPlugin未被继承，则大概率WebsocketPlugin也不需要被继承，可以直接复用。</p>
<p>2）若需要继承WebsocketPlugin，则简单重写GetSmartMessageType接口，在派生类构造中调用WebsocketPlugin::WebsocketPlugin(std::string config_path)即可。</p>
</div>
</div>
<div class="section" id="id6">
<h2>运行部署<a class="headerlink" href="#id6" title="永久链接至标题">¶</a></h2>
<p>打包的示例solution，需要提供Method的工厂接口实现，main函数中需要完成Plugin的创建与启动。</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">namespace</span> <span class="n">xstream</span> <span class="p">{</span>
<span class="k">namespace</span> <span class="n">method_factory</span> <span class="p">{</span>
<span class="n">MethodPtr</span> <span class="n">CreateMethod</span><span class="p">(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="o">&amp;</span><span class="n">method_name</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// 这里的类型名字需要和workflow中配置的method的type类型一致。</span>
  <span class="k">if</span> <span class="p">(</span><span class="s">&quot;MultitaskPredictMethod&quot;</span> <span class="o">==</span> <span class="n">method_name</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">MethodPtr</span><span class="p">(</span><span class="k">new</span> <span class="n">MultitaskPredictMethod</span><span class="p">());</span>
  <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="s">&quot;MultitaskPostProcessMethod&quot;</span> <span class="o">==</span> <span class="n">method_name</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">MethodPtr</span><span class="p">(</span><span class="k">new</span> <span class="n">MultitaskPostProcessMethod</span><span class="p">());</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">MethodPtr</span><span class="p">();</span>
  <span class="p">}</span>
<span class="p">}</span>
<span class="p">}</span>  <span class="c1">//  namespace method_factory</span>
<span class="p">}</span>  <span class="c1">//  namespace xstream</span>
</pre></div>
</div>
<p>main函数的参考实现如下：</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">static</span> <span class="kt">void</span> <span class="nf">signal_handle</span><span class="p">(</span><span class="kt">int</span> <span class="n">param</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;recv signal &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">param</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;, stop&quot;</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">param</span> <span class="o">==</span> <span class="n">SIGINT</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">exit_</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">vio_config_file</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">smart_config_file</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">websocket_config_file</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">3</span><span class="p">]);</span>

  <span class="n">signal</span><span class="p">(</span><span class="n">SIGINT</span><span class="p">,</span> <span class="n">signal_handle</span><span class="p">);</span>
  <span class="n">signal</span><span class="p">(</span><span class="n">SIGPIPE</span><span class="p">,</span> <span class="n">signal_handle</span><span class="p">);</span>

  <span class="c1">// 创建plugin对象</span>
  <span class="k">auto</span> <span class="n">vio_plg</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">VioPlugin</span><span class="o">&gt;</span><span class="p">(</span><span class="n">vio_config_file</span><span class="p">);</span>
  <span class="k">auto</span> <span class="n">smart_plg</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">SmartPlugin</span><span class="o">&gt;</span><span class="p">(</span><span class="n">smart_config_file</span><span class="p">);</span>
  <span class="k">auto</span> <span class="n">websocket_plg</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">WebsocketPlugin</span><span class="o">&gt;</span><span class="p">(</span><span class="n">websocket_config_file</span><span class="p">);</span>
 
  <span class="c1">// 分别初始化</span>
  <span class="k">auto</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">vio_plg</span><span class="o">-&gt;</span><span class="n">Init</span><span class="p">();</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="n">ret</span> <span class="o">=</span> <span class="n">smart_plg</span><span class="o">-&gt;</span><span class="n">Init</span><span class="p">();</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="n">ret</span> <span class="o">=</span> <span class="n">websocket_plg</span><span class="o">-&gt;</span><span class="n">Init</span><span class="p">();</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>
  
  <span class="c1">// 分别启动</span>
  <span class="n">vio_plg</span><span class="o">-&gt;</span><span class="n">Start</span><span class="p">();</span>
  <span class="n">smart_plg</span><span class="o">-&gt;</span><span class="n">Start</span><span class="p">();</span>
  <span class="n">websocket_plg</span><span class="o">-&gt;</span><span class="n">Start</span><span class="p">();</span>
  
  <span class="k">while</span> <span class="p">(</span><span class="o">!</span><span class="n">exit_</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">sleep_for</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">microseconds</span><span class="p">(</span><span class="mi">40</span><span class="p">));</span>
  <span class="p">}</span>

  <span class="n">vio_plg</span><span class="o">-&gt;</span><span class="n">Stop</span><span class="p">();</span>
  <span class="n">vio_plg</span><span class="o">-&gt;</span><span class="n">DeInit</span><span class="p">();</span>
  <span class="n">vio_plg</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
  <span class="n">smart_plg</span><span class="o">-&gt;</span><span class="n">Stop</span><span class="p">();</span>
  <span class="n">websocket_plg</span><span class="o">-&gt;</span><span class="n">Stop</span><span class="p">();</span>
  <span class="n">smart_plg</span><span class="o">-&gt;</span><span class="n">DeInit</span><span class="p">();</span>
  <span class="n">websocket_plg</span><span class="o">-&gt;</span><span class="n">DeInit</span><span class="p">();</span>
  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="id7">
<h2>模型集成示例说明<a class="headerlink" href="#id7" title="永久链接至标题">¶</a></h2>
<p>示例中使用的模型为YoloV3与MobilenetV2。通过IotVioPlugin获取图像，开发两个模型的预测Method与后处理Method，通过SmartPlugin完成模型预测。最后通过WebsocketPlugin将图像与感知结果发送给PC浏览器。</p>
<div class="section" id="id8">
<h3>模型描述<a class="headerlink" href="#id8" title="永久链接至标题">¶</a></h3>
<p>YoloV3模型文件yolov3_nv12_hybrid_horizonrt.bin，模型信息描述如下【通过bpu_predict接口获取模型信息】：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Input num:1：
input[0]: data type: BPU_TYPE_IMG_YUV_NV12, shape:(1,3,416,416), layout: BPU_LAYOUT_NCHW, aligned shape:(1,4,416,416)

Output num:3
output[0]: data type: BPU_TYPE_TENSOR_F32, shape:(1,13,13,255), layout: BPU_LAYOUT_NHWC, aligned shape:(1,13,13,255)
output[1]: data type: BPU_TYPE_TENSOR_F32, shape:(1,26,26,255), layout: BPU_LAYOUT_NHWC, aligned shape:(1,26,26,255)
output[2]: data type: BPU_TYPE_TENSOR_F32, shape:(1,52,52,255), layout: BPU_LAYOUT_NHWC, aligned shape:(1,52,52,255)
</pre></div>
</div>
<p>MobilenetV2模型文件mobilenetv2_nv12_hybrid_horizonrt.bin，模型信息描述如下：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Input num:1：
input[0]: data type: BPU_TYPE_IMG_YUV_NV12, shape:(1,3,224,224), layout: BPU_LAYOUT_NCHW, aligned shape:(1,4,224,224)

Output num:1
output[0]: data type: BPU_TYPE_TENSOR_F32, shape:(1,1000,1,1), layout: BPU_LAYOUT_NCHW, aligned shape:(1,1000,1,1)
</pre></div>
</div>
</div>
<div class="section" id="id9">
<h3>模型预测与后处理Method开发<a class="headerlink" href="#id9" title="永久链接至标题">¶</a></h3>
<p>以模型YoloV3与MobilenetV2为例，集成检测+分类的预测与后处理Method开发。其中检测包括Yolov3PredictMethod、Yolov3PostProcessMethod，分类包括Mobilenetv2PredictMethod、Mobilenetv2PostProcessMethod。详细代码可以参考<code class="docutils literal notranslate"><span class="pre">common/xstream/framework/tutorials/stage10</span></code>。</p>
<p>框架中已包括模型预测+后处理的Method基础类，即DnnPredictMethod与DnnPostProcessMethod。用户集成具体的模型时，需要根据需要实现基类中的成员函数，具体可以参考<a class="reference external" href="#DnnPredictMethod">DnnPredictMethod</a>.</p>
<div class="section" id="yolov3">
<h4>YoloV3<a class="headerlink" href="#yolov3" title="永久链接至标题">¶</a></h4>
<p>根据模型描述信息，该模型的输入是416x416大小的nv12数据，在预测方法Yolov3PredictMethod中，核心工作是在函数<code class="docutils literal notranslate"><span class="pre">PrepareInputData()</span></code>中准备模型的输入数据。由于输入是nv12数据，所以可以直接使用金字塔图像数据，因此需要<strong>配置金字塔层数</strong>，详细可以参考<a class="reference external" href="#IotVioPlugin%E9%87%91%E5%AD%97%E5%A1%94%E9%85%8D%E7%BD%AE">IotVioPlugin金字塔配置</a>，这里不展开描述金字塔的配置。</p>
<p>若对金字塔图像直接缩放，缩放至416x416，势必会产生形变。为了保证模型效果，我们对图像做了padding后，再进行缩放。思路为：直接在原图底部填充黑色，将原图padding为宽高相同的图像（padding_image），再将padding_image缩放至416x416大小。这里为了减小计算量，我们选择合适的金字塔层做输入。</p>
<p>以原图1920x1080为例，金字塔第0层大小为1920x1080，第4层为960x540，第8层为480x270。yolov3模型输入大小是416x416，我们避免padding过多影响算法效果，选择宽高都大于模型输入大小的金字塔图像作为输入。需要以第4层(960x540)为基础层，padding到960x960大小，再缩放到416x416。</p>
<p>以原图3840x2160为例，金字塔第0层大小为3840x2160，第4层为1920x1080，第8层为960x540，需要以第8层(960x540)为基础层，padding到960x960大小，再缩放到416x416。</p>
<p>以原图4000*3000为例，金字塔第0层大小为4000x3000，第4层为2000x1500，第8层为1000x750，第12层为500x375。需要以第8层(1000x750)为基础层，padding到1000x1000大小，再缩放到416x416。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>// PrepareInputData的逻辑
// 参考common/xstream/framework/tutorials/stage10/method/Yolov3PredictMethod
1. 从指定金字塔层中取数据，并检查图像宽高大小是否大于模型输入大小(416x416)。若不满足需要报错，一般是vio金字塔配置错误;
2. 申请input_tensor和output_tensor, 基类已实现，可以直接调用;
3. 申请padding_image空间，封装为BPU_Tensor结构，注意使用结束需要释放;
4. 复制金字塔图像数据到padding_image;
5. 缩放padding_image数据到input_tensor;
6. 释放padding_image;
</pre></div>
</div>
<p>另外，由于模型输出的检测结果是基于输入数据的，所以后续需要缩放到原分辨率大小(后处理中)，这里预测前需要获取原图分辨率<code class="docutils literal notranslate"><span class="pre">GetSrcImageSize()</span></code>。</p>
<p>后处理中，核心工作是在函数<code class="docutils literal notranslate"><span class="pre">ParseDnnResult()</span></code>中解析bpu输出结果output_tensor。需要注意的是，这里直接解析出的检测结果是基于输入数据的分辨率，需要将其坐标映射回原图分辨率。假设原图大小(金字塔第0层)1920x1080，金字塔第4层960x540，取金字塔第4层960x540，padding到960x960大小，再缩放到416x416后输入模型预测。代码可参考<code class="docutils literal notranslate"><span class="pre">common/xstream/framework/tutorials/stage10/method/Yolov3PostProcessMethod</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="n">映射关系</span><span class="p">,</span> <span class="n">原图坐标</span><span class="p">(</span><span class="n">x</span><span class="s1">&#39;, y&#39;</span><span class="p">),</span> <span class="n">输出结果</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">x</span><span class="s1">&#39; = [x * (960.0 / 416.0)] * (1980 / 960)</span>
<span class="n">y</span><span class="s1">&#39; = [y * (960.0 / 416.0)] * (1080 / 540)</span>
</pre></div>
</div>
<p>这里还需注意的是，由于对原图做了底部的padding，因此需要对映射后的坐标(x’, y’)【主要是y’】，限制在原图坐标范围内。</p>
<p>后处理解析的检测框使用<code class="docutils literal notranslate"><span class="pre">hobot::vision::BBox</span></code>数据结构来表示(定义在common/xstream/vision_type/include/horizon/vision_type/vision_type.hpp)。此外，在函数<code class="docutils literal notranslate"><span class="pre">ParseDnnResult()</span></code>中还需要将解析后的数据封装为xstream-frame框架支持的BaseData数据结构。由于全图可能存在多个目标，结果会有多个检测框，这里需要使用派生数据结构xstream::BaseDataVector，将检测框封装到成员变量datas_中，Yolov3PostProcessMethod的输出数据结构是xstream::BaseDataVector&lt;xstream::XStreamData<a class="reference external" href="hobot::vision::BBox">hobot::vision::BBox</a>&gt;.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">struct</span> <span class="nl">BaseDataVector</span> <span class="p">:</span> <span class="k">public</span> <span class="n">BaseData</span> <span class="p">{</span>
  <span class="n">BaseDataVector</span><span class="p">();</span>
  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">BaseDataPtr</span><span class="o">&gt;</span> <span class="n">datas_</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">Dtype</span><span class="o">&gt;</span>
<span class="k">struct</span> <span class="nl">XStreamData</span> <span class="p">:</span> <span class="k">public</span> <span class="n">BaseData</span> <span class="p">{</span>
  <span class="n">Dtype</span> <span class="n">value</span><span class="p">;</span>
  <span class="n">XStreamData</span><span class="p">()</span> <span class="p">{}</span>
  <span class="k">explicit</span> <span class="n">XStreamData</span><span class="p">(</span><span class="k">const</span> <span class="n">Dtype</span><span class="o">&amp;</span> <span class="n">val</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">val</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
</div>
<div class="section" id="mobilenetv2">
<h4>MobilenetV2<a class="headerlink" href="#mobilenetv2" title="永久链接至标题">¶</a></h4>
<p>根据模型描述信息，该模型的输入是224x224大小的nv12数据，该分类模型需要将roi数据送入模型进行预测。因此在预测方法Mobilenetv2PredictMethod中，需要输入的数据包括金字塔数据以及Yolov3PostProcessMethod输出的roi数据。在函数<code class="docutils literal notranslate"><span class="pre">PrepareInputData()</span></code>中，核心操作是抠取原图上的roi数据，并缩放到224x224大小。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>// PrepareInputData的逻辑
// 参考common/xstream/framework/tutorials/stage10/method/Mobilenetv2PredictMethod
1. 检查输入数据，包括金字塔图像image，以及roi框;
2. 获取金字塔原图数据，设置roi信息, 注意按照Yolov3PostProcessMethod输出的roi格式进行解析;
3. 申请input_tensor和output_tensor, 基类已实现，可以直接调用;
4. 调用bpu接口将原图中roi数据缩放到input_tensor中
</pre></div>
</div>
<p>后处理中，核心工作是在函数<code class="docutils literal notranslate"><span class="pre">ParseDnnResult()</span></code>中解析bpu输出结果output_tensor，并封装成框架兼容的BaseData数据类型。与Yolov3PostProcessMethod输出类似，这里同样用<code class="docutils literal notranslate"><span class="pre">hobot::vision::BBox</span></code>数据结构来表示分类结果。Mobilenetv2PostProcessMethod的输出数据结构是xstream::BaseDataVector&lt;xstream::XStreamData<a class="reference external" href="hobot::vision::BBox">hobot::vision::BBox</a>&gt;.
详细可参考<code class="docutils literal notranslate"><span class="pre">common/xstream/framework/tutorials/stage10/method/Mobilenetv2PostProcessMethod</span></code>.</p>
</div>
</div>
<div class="section" id="id10">
<h3>SmartPlugin<a class="headerlink" href="#id10" title="永久链接至标题">¶</a></h3>
<p>在solution_zoo/yolov3_mobilenetv2_example目录下实现ExampleSmartplugin继承SmartPlugin,拓展新的消息ExampleCustomSmartMessage，其消息类型为EXAMPLE_SMART_MESSAGE。</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="cp">#define EXAMPLE_SMART_MESSAGE &quot;EXAMPLE_XPLUGIN_SMART_MESSAGE&quot;</span>
<span class="n">XPLUGIN_REGISTER_MSG_TYPE</span><span class="p">(</span><span class="n">EXAMPLE_XPLUGIN_SMART_MESSAGE</span><span class="p">)</span>

<span class="k">struct</span> <span class="nl">ExampleCustomSmartMessage</span> <span class="p">:</span> <span class="n">CustomSmartMessage</span> <span class="p">{</span>
  <span class="k">explicit</span> <span class="n">ExampleCustomSmartMessage</span><span class="p">(</span>
    <span class="n">xstream</span><span class="o">::</span><span class="n">OutputDataPtr</span> <span class="n">out</span><span class="p">)</span> <span class="o">:</span> <span class="n">CustomSmartMessage</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">type_</span> <span class="o">=</span> <span class="n">EXAMPLE_SMART_MESSAGE</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">Serialize</span><span class="p">(</span><span class="kt">int</span> <span class="n">ori_w</span><span class="p">,</span> <span class="kt">int</span> <span class="n">ori_h</span><span class="p">,</span> <span class="kt">int</span> <span class="n">dst_w</span><span class="p">,</span> <span class="kt">int</span> <span class="n">dst_h</span><span class="p">)</span> <span class="k">override</span><span class="p">;</span>
<span class="p">};</span>

<span class="k">class</span> <span class="nc">ExampleSmartPlugin</span> <span class="o">:</span> <span class="k">public</span> <span class="n">SmartPlugin</span> <span class="p">{</span>
 <span class="k">public</span><span class="o">:</span>
  <span class="k">explicit</span> <span class="n">ExampleSmartPlugin</span><span class="p">(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span> <span class="n">config_file</span><span class="p">);</span>

 <span class="k">private</span><span class="o">:</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">GetWorkflowInputImageName</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">return</span> <span class="s">&quot;image&quot;</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">CustomSmartMessage</span><span class="o">&gt;</span>
  <span class="n">CreateSmartMessage</span><span class="p">(</span><span class="n">xstream</span><span class="o">::</span><span class="n">OutputDataPtr</span> <span class="n">xstream_out</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">ExampleCustomSmartMessage</span><span class="o">&gt;</span><span class="p">(</span><span class="n">xstream_out</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
<p>这里定义了新的消息EXAMPLE_SMART_MESSAGE，需要注意定义好消息后，要调用XPLUGIN_REGISTER_MSG_TYPE注册消息。
派生类ExampleSmartPlugin实现接口CreateSmartMessage创建新定义的消息ExampleCustomSmartMessage。
派生类ExampleCustomSmartMessage实现了感知结果的序列化接口Serialize,用于序列化模型输出结果，具体实现如下：</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">ExampleCustomSmartMessage</span><span class="o">::</span><span class="n">Serialize</span><span class="p">(</span>
  <span class="kt">int</span> <span class="n">ori_w</span><span class="p">,</span> <span class="kt">int</span> <span class="n">ori_h</span><span class="p">,</span> <span class="kt">int</span> <span class="n">dst_w</span><span class="p">,</span> <span class="kt">int</span> <span class="n">dst_h</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">HOBOT_CHECK</span><span class="p">(</span><span class="n">ori_w</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">ori_h</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">dst_w</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">dst_h</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
      <span class="o">&lt;&lt;</span> <span class="s">&quot;Serialize param error&quot;</span><span class="p">;</span>
  <span class="kt">float</span> <span class="n">x_ratio</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">dst_w</span> <span class="o">/</span> <span class="n">ori_w</span><span class="p">;</span>
  <span class="kt">float</span> <span class="n">y_ratio</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">dst_h</span> <span class="o">/</span> <span class="n">ori_h</span><span class="p">;</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">proto_str</span><span class="p">;</span>
  <span class="n">x3</span><span class="o">::</span><span class="n">FrameMessage</span> <span class="n">proto_frame_message</span><span class="p">;</span>
  <span class="n">proto_frame_message</span><span class="p">.</span><span class="n">set_timestamp_</span><span class="p">(</span><span class="n">time_stamp</span><span class="p">);</span>
  <span class="k">auto</span> <span class="n">smart_msg</span> <span class="o">=</span> <span class="n">proto_frame_message</span><span class="p">.</span><span class="n">mutable_smart_msg_</span><span class="p">();</span>
  <span class="n">smart_msg</span><span class="o">-&gt;</span><span class="n">set_timestamp_</span><span class="p">(</span><span class="n">time_stamp</span><span class="p">);</span>
  <span class="n">smart_msg</span><span class="o">-&gt;</span><span class="n">set_error_code_</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>

  <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span>
      <span class="n">xstream</span><span class="o">::</span><span class="n">XStreamData</span><span class="o">&lt;</span><span class="n">hobot</span><span class="o">::</span><span class="n">vision</span><span class="o">::</span><span class="n">BBox</span><span class="o">&gt;&gt;&gt;</span> <span class="n">detected_box_list</span><span class="p">;</span>

  <span class="k">for</span> <span class="p">(</span><span class="k">const</span> <span class="k">auto</span> <span class="o">&amp;</span><span class="nl">output</span> <span class="p">:</span> <span class="n">smart_result</span><span class="o">-&gt;</span><span class="n">datas_</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">LOGD</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;output name: &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">output</span><span class="o">-&gt;</span><span class="n">name_</span><span class="p">;</span>

    <span class="c1">// output name must be same as workflow global output</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">output</span><span class="o">-&gt;</span><span class="n">name_</span> <span class="o">==</span> <span class="s">&quot;detect_box&quot;</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">auto</span> <span class="n">box_list</span> <span class="o">=</span> <span class="k">dynamic_cast</span><span class="o">&lt;</span><span class="n">xstream</span><span class="o">::</span><span class="n">BaseDataVector</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">get</span><span class="p">());</span>
        <span class="n">LOGD</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;box type: &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">output</span><span class="o">-&gt;</span><span class="n">name_</span>
           <span class="o">&lt;&lt;</span> <span class="s">&quot;, box size: &quot;</span> <span class="o">&lt;&lt;</span> <span class="n">box_list</span><span class="o">-&gt;</span><span class="n">datas_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">box_list</span><span class="o">-&gt;</span><span class="n">datas_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
          <span class="k">auto</span> <span class="n">detect_box</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">static_pointer_cast</span><span class="o">&lt;</span>
              <span class="n">xstream</span><span class="o">::</span><span class="n">XStreamData</span><span class="o">&lt;</span><span class="n">hobot</span><span class="o">::</span><span class="n">vision</span><span class="o">::</span><span class="n">BBox</span><span class="o">&gt;&gt;</span><span class="p">(</span><span class="n">box_list</span><span class="o">-&gt;</span><span class="n">datas_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
          <span class="n">detected_box_list</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">detect_box</span><span class="p">);</span>

          <span class="k">auto</span> <span class="n">target</span> <span class="o">=</span> <span class="n">smart_msg</span><span class="o">-&gt;</span><span class="n">add_targets_</span><span class="p">();</span>
          <span class="n">target</span><span class="o">-&gt;</span><span class="n">set_type_</span><span class="p">(</span><span class="n">detect_box</span><span class="o">-&gt;</span><span class="n">value</span><span class="p">.</span><span class="n">category_name</span><span class="p">);</span>
          <span class="n">target</span><span class="o">-&gt;</span><span class="n">set_track_id_</span><span class="p">(</span><span class="n">detect_box</span><span class="o">-&gt;</span><span class="n">value</span><span class="p">.</span><span class="n">id</span><span class="p">);</span>
          <span class="k">auto</span> <span class="n">proto_box</span> <span class="o">=</span> <span class="n">target</span><span class="o">-&gt;</span><span class="n">add_boxes_</span><span class="p">();</span>
          <span class="k">auto</span> <span class="n">point1</span> <span class="o">=</span> <span class="n">proto_box</span><span class="o">-&gt;</span><span class="n">mutable_top_left_</span><span class="p">();</span>
          <span class="n">point1</span><span class="o">-&gt;</span><span class="n">set_x_</span><span class="p">(</span><span class="n">detect_box</span><span class="o">-&gt;</span><span class="n">value</span><span class="p">.</span><span class="n">x1</span> <span class="o">*</span> <span class="n">x_ratio</span><span class="p">);</span>
          <span class="n">point1</span><span class="o">-&gt;</span><span class="n">set_y_</span><span class="p">(</span><span class="n">detect_box</span><span class="o">-&gt;</span><span class="n">value</span><span class="p">.</span><span class="n">y1</span> <span class="o">*</span> <span class="n">y_ratio</span><span class="p">);</span>
          <span class="n">point1</span><span class="o">-&gt;</span><span class="n">set_score_</span><span class="p">(</span><span class="n">detect_box</span><span class="o">-&gt;</span><span class="n">value</span><span class="p">.</span><span class="n">score</span><span class="p">);</span>
          <span class="k">auto</span> <span class="n">point2</span> <span class="o">=</span> <span class="n">proto_box</span><span class="o">-&gt;</span><span class="n">mutable_bottom_right_</span><span class="p">();</span>
          <span class="n">point2</span><span class="o">-&gt;</span><span class="n">set_x_</span><span class="p">(</span><span class="n">detect_box</span><span class="o">-&gt;</span><span class="n">value</span><span class="p">.</span><span class="n">x2</span> <span class="o">*</span> <span class="n">x_ratio</span><span class="p">);</span>
          <span class="n">point2</span><span class="o">-&gt;</span><span class="n">set_y_</span><span class="p">(</span><span class="n">detect_box</span><span class="o">-&gt;</span><span class="n">value</span><span class="p">.</span><span class="n">y2</span> <span class="o">*</span> <span class="n">y_ratio</span><span class="p">);</span>
          <span class="n">point2</span><span class="o">-&gt;</span><span class="n">set_score_</span><span class="p">(</span><span class="n">detect_box</span><span class="o">-&gt;</span><span class="n">value</span><span class="p">.</span><span class="n">score</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">output</span><span class="o">-&gt;</span><span class="n">name_</span> <span class="o">==</span> <span class="s">&quot;classify&quot;</span><span class="p">)</span> <span class="p">{</span>
       <span class="k">auto</span> <span class="n">box_list</span> <span class="o">=</span> <span class="k">dynamic_cast</span><span class="o">&lt;</span><span class="n">xstream</span><span class="o">::</span><span class="n">BaseDataVector</span> <span class="o">*&gt;</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">get</span><span class="p">());</span>
       <span class="k">if</span> <span class="p">(</span><span class="n">box_list</span><span class="o">-&gt;</span><span class="n">datas_</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">!=</span> <span class="n">detected_box_list</span><span class="p">.</span><span class="n">size</span><span class="p">())</span> <span class="p">{</span>
         <span class="n">LOGE</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;classify box size not equal detect box size&quot;</span><span class="p">;</span>
       <span class="p">}</span>
      <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">box_list</span><span class="o">-&gt;</span><span class="n">datas_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">auto</span> <span class="n">classify_box</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">static_pointer_cast</span><span class="o">&lt;</span>
              <span class="n">xstream</span><span class="o">::</span><span class="n">XStreamData</span><span class="o">&lt;</span><span class="n">hobot</span><span class="o">::</span><span class="n">vision</span><span class="o">::</span><span class="n">BBox</span><span class="o">&gt;&gt;</span><span class="p">(</span><span class="n">box_list</span><span class="o">-&gt;</span><span class="n">datas_</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
        <span class="k">auto</span> <span class="n">target</span> <span class="o">=</span> <span class="n">smart_msg</span><span class="o">-&gt;</span><span class="n">mutable_targets_</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
        <span class="k">auto</span> <span class="n">attrs</span> <span class="o">=</span> <span class="n">target</span><span class="o">-&gt;</span><span class="n">add_attributes_</span><span class="p">();</span>
        <span class="n">attrs</span><span class="o">-&gt;</span><span class="n">set_type_</span><span class="p">(</span><span class="s">&quot;label&quot;</span><span class="p">);</span>
        <span class="n">attrs</span><span class="o">-&gt;</span><span class="n">set_value_string_</span><span class="p">(</span><span class="n">classify_box</span><span class="o">-&gt;</span><span class="n">value</span><span class="p">.</span><span class="n">category_name</span><span class="p">);</span>
        <span class="n">attrs</span><span class="o">-&gt;</span><span class="n">set_score_</span><span class="p">(</span><span class="n">classify_box</span><span class="o">-&gt;</span><span class="n">value</span><span class="p">.</span><span class="n">score</span><span class="p">);</span>
      <span class="p">}</span>
    <span class="p">}</span>
  <span class="p">}</span>

  <span class="n">proto_frame_message</span><span class="p">.</span><span class="n">SerializeToString</span><span class="p">(</span><span class="o">&amp;</span><span class="n">proto_str</span><span class="p">);</span>
  <span class="k">return</span> <span class="n">proto_str</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>这里的序列化主要是将模型输出的检测框，以及对应的type和label封装成pb消息。需要注意的是，对模型输出处理时，output-&gt;name_要和workflow配置文件中的output名字保持一致。</p>
</div>
<div class="section" id="id11">
<h3>WebSocketPlugin<a class="headerlink" href="#id11" title="永久链接至标题">¶</a></h3>
<p>yolov3_mobilenetv2_example实现派生类ExamapleWebsocketPlugin，用于接收ExampleSmartPlugin产生的消息，然后将消息发送给前端展示。</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ExampleWebsocketPlugin</span> <span class="o">:</span> <span class="k">public</span> <span class="n">WebsocketPlugin</span> <span class="p">{</span>
 <span class="k">public</span><span class="o">:</span>
  <span class="k">explicit</span> <span class="n">ExampleWebsocketPlugin</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">config_path</span><span class="p">);</span>

 <span class="k">protected</span><span class="o">:</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">GetSmartMessageType</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">EXAMPLE_SMART_MESSAGE</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">};</span>
</pre></div>
</div>
<p>派生类实现接口GetSmartMessageType()，返回ExampleSmartPlugin产生的消息类型，用于基类WebsocketPlugin注册消息类型时使用，以获得对应的感知结果。</p>
</div>
<div class="section" id="main">
<h3>main 函数实现<a class="headerlink" href="#main" title="永久链接至标题">¶</a></h3>
<p>基于派生类ExampleSmartPlugin，ExampleWebsocketPlugin以及VioPlugin，我们可以串联完整的workflow，实现yolov3_solution。</p>
<div class="highlight-C++ notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">vio_config_file</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">smart_config_file</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">websocket_config_file</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">3</span><span class="p">]);</span>

  <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">log_level</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">4</span><span class="p">]);</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">log_level</span> <span class="o">==</span> <span class="s">&quot;-i&quot;</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">SetLogLevel</span><span class="p">(</span><span class="n">HOBOT_LOG_INFO</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">log_level</span> <span class="o">==</span> <span class="s">&quot;-d&quot;</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">SetLogLevel</span><span class="p">(</span><span class="n">HOBOT_LOG_DEBUG</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">log_level</span> <span class="o">==</span> <span class="s">&quot;-w&quot;</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">SetLogLevel</span><span class="p">(</span><span class="n">HOBOT_LOG_WARN</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">log_level</span> <span class="o">==</span> <span class="s">&quot;-e&quot;</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">SetLogLevel</span><span class="p">(</span><span class="n">HOBOT_LOG_ERROR</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="n">log_level</span> <span class="o">==</span> <span class="s">&quot;-f&quot;</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">SetLogLevel</span><span class="p">(</span><span class="n">HOBOT_LOG_FATAL</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="n">LOGE</span> <span class="o">&lt;&lt;</span> <span class="s">&quot;log option: [-i/-d/-w/-f] &quot;</span><span class="p">;</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">signal</span><span class="p">(</span><span class="n">SIGINT</span><span class="p">,</span> <span class="n">signal_handle</span><span class="p">);</span>
  <span class="n">signal</span><span class="p">(</span><span class="n">SIGPIPE</span><span class="p">,</span> <span class="n">signal_handle</span><span class="p">);</span>

  <span class="c1">// 创建plugin对象</span>
  <span class="k">auto</span> <span class="n">vio_plg</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">VioPlugin</span><span class="o">&gt;</span><span class="p">(</span><span class="n">vio_config_file</span><span class="p">);</span>
  <span class="k">auto</span> <span class="n">smart_plg</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">ExampleSmartPlugin</span><span class="o">&gt;</span><span class="p">(</span><span class="n">smart_config_file</span><span class="p">);</span>
  <span class="k">auto</span> <span class="n">websocket_plg</span> <span class="o">=</span>
  <span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">ExampleWebsocketPlugin</span><span class="o">&gt;</span><span class="p">(</span><span class="n">websocket_config_file</span><span class="p">);</span>

  <span class="k">auto</span> <span class="n">ret</span> <span class="o">=</span> <span class="n">vio_plg</span><span class="o">-&gt;</span><span class="n">Init</span><span class="p">();</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">ret</span> <span class="o">=</span> <span class="n">smart_plg</span><span class="o">-&gt;</span><span class="n">Init</span><span class="p">();</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">ret</span> <span class="o">=</span> <span class="n">websocket_plg</span><span class="o">-&gt;</span><span class="n">Init</span><span class="p">();</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">ret</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">return</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="n">vio_plg</span><span class="o">-&gt;</span><span class="n">Start</span><span class="p">();</span>
  <span class="n">smart_plg</span><span class="o">-&gt;</span><span class="n">Start</span><span class="p">();</span>
  <span class="n">websocket_plg</span><span class="o">-&gt;</span><span class="n">Start</span><span class="p">();</span>

  <span class="k">while</span> <span class="p">(</span><span class="o">!</span><span class="n">exit_</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">std</span><span class="o">::</span><span class="n">this_thread</span><span class="o">::</span><span class="n">sleep_for</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">chrono</span><span class="o">::</span><span class="n">microseconds</span><span class="p">(</span><span class="mi">40</span><span class="p">));</span>
  <span class="p">}</span>

  <span class="n">vio_plg</span><span class="o">-&gt;</span><span class="n">Stop</span><span class="p">();</span>
  <span class="n">vio_plg</span><span class="o">-&gt;</span><span class="n">DeInit</span><span class="p">();</span>
  <span class="n">vio_plg</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
  <span class="n">smart_plg</span><span class="o">-&gt;</span><span class="n">Stop</span><span class="p">();</span>
  <span class="n">websocket_plg</span><span class="o">-&gt;</span><span class="n">Stop</span><span class="p">();</span>
  <span class="n">smart_plg</span><span class="o">-&gt;</span><span class="n">DeInit</span><span class="p">();</span>
  <span class="n">websocket_plg</span><span class="o">-&gt;</span><span class="n">DeInit</span><span class="p">();</span>
  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>在main函数中，分别创建VioPlugin,ExampleSmartPlugin,ExampleWebsocketplugin，并调用Init和Start接口，运行workflow。其中smart_config_file为ExampleSmartPlugin的配置文件，在这里为yolov3_mobilenetv2_example/configs/solution_yolov3.json。</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="nt">&quot;xstream_workflow_file&quot;</span><span class="p">:</span> <span class="s2">&quot;./yolov3_solution/configs/workflow_yolov3.json&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>其中配置了soluton的workflow文件，即./yolov3_solution/configs/workflow_yolov3.json。</p>
</div>
<div class="section" id="yolov3-solution">
<h3>运行yolov3_solution<a class="headerlink" href="#yolov3-solution" title="永久链接至标题">¶</a></h3>
<p>完成以上步骤后，生成yolov3_solution可执行文件。
在部署包里运行新增加的yolov3_solution，还需要在run.sh里增加相应支持。
首先在choose_solution_func中增加yolov3选项：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>  <span class="nb">echo</span> -e <span class="s1">&#39;\t1.  face&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t2.  face_recog&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t3.  body&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t4.  xbox&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t5.  behavior&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t7.  video_box&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t8.  tv_uvc&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t9.  face_body_multisource&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t10. apa&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t11. multi_input_hapi&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t12. apa_test&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t13. ssd_test&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t14. vio_test&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t15. multi_input_hapi_ipm&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t16. matting&#39;</span>
  <span class="nb">echo</span> -e <span class="s1">&#39;\t17. yolov3_mobilenetv3_example&#39;</span>
</pre></div>
</div>
<p>然后在对应的case处增加solution的执行命令：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>    <span class="m">17</span><span class="o">)</span>  <span class="nb">echo</span> -e <span class="s2">&quot;\033[33m You choose 17:yolvo3_mobilenetv2  \033[0m&quot;</span>
           choose_platform_func
           <span class="nb">echo</span> <span class="s2">&quot;vio_cnfig_file: </span><span class="nv">$vio_cfg_file</span><span class="s2">&quot;</span>
           ./yolov3_solution/yolov3_solution <span class="nv">$vio_cfg_file</span> ./yolov3_solution/configs/solution_yolov3.json ./configs/visualplugin_body.json -<span class="si">${</span><span class="nv">log_level</span><span class="si">}</span> normal
      <span class="p">;;</span>
</pre></div>
</div>
<p>这样就完成了yolov3_solution从编译到部署的全部步骤。</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; 版权所有 2020, Horizon Robotics.

    </p>
  </div>
    
    
    
    利用 <a href="https://www.sphinx-doc.org/">Sphinx</a> 构建，使用了 
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">主题</a>
    
    由 <a href="https://readthedocs.org">Read the Docs</a>开发. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>